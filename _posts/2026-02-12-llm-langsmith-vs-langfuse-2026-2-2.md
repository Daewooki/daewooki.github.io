---
title: "LLM ì•±ì—ì„œ â€œì–´ë””ì„œ í„°ì¡Œê³ , ì™œ ë¹„ì‹¸ì¡ŒëŠ”ì§€â€ ëê¹Œì§€ ì¶”ì í•˜ê¸°: LangSmith vs Langfuse (2026ë…„ 2ì›” ê´€ì )"
date: 2026-02-12 02:55:15 +0900
categories: [AI, MLOps]
tags: [ai, mlops, trend, 2026-02]
---

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7990TVG7C7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7990TVG7C7');
</script>

## ë“¤ì–´ê°€ë©°
LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì „í†µì ì¸ APM(Application Performance Monitoring)ë§Œìœ¼ë¡œëŠ” ìš´ì˜ì´ ì–´ë µìŠµë‹ˆë‹¤. ì´ìœ ëŠ” ë‹¨ìˆœí•©ë‹ˆë‹¤. ì¥ì• ê°€ â€œHTTP 500â€ì²˜ëŸ¼ ëª…í™•í•˜ì§€ ì•Šê³ , í’ˆì§ˆ ì €í•˜ë„ â€œì •ë‹µ/ì˜¤ë‹µâ€ìœ¼ë¡œ ë–¨ì–´ì§€ì§€ ì•Šìœ¼ë©°, ë¹„ìš©ì€ â€œí† í°/ìºì‹œ/ë¦¬íŠ¸ë¼ì´/íˆ´ í˜¸ì¶œâ€ì²˜ëŸ¼ ì‹¤í–‰ ê²½ë¡œì— ë”°ë¼ ë¶„ì‚°ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  
ê·¸ë˜ì„œ 2025~2026ë…„ì˜ LLM ObservabilityëŠ” **trace ì¤‘ì‹¬(ìš”ì²­ 1ê±´ì˜ ì‹¤í–‰ì„ íŠ¸ë¦¬ í˜•íƒœë¡œ)**ìœ¼ë¡œ ë¹ ë¥´ê²Œ ìˆ˜ë ´í–ˆê³ , ê·¸ ìœ„ì— **ë””ë²„ê¹… + ë¹„ìš© ì¶”ì  + í’ˆì§ˆ í‰ê°€(evals)**ë¥¼ í•œ í™”ë©´ì—ì„œ ë¬¶ëŠ” ìª½ìœ¼ë¡œ ì§„í™”í–ˆìŠµë‹ˆë‹¤.

ì´ ê¸€ì—ì„œëŠ” 2026ë…„ 2ì›” ê¸°ì¤€ìœ¼ë¡œ í˜„ì—…ì—ì„œ ê°€ì¥ ìì£¼ ë¹„êµë˜ëŠ” **LangSmith**ì™€ **Langfuse**ë¥¼ â€œëª¨ë‹ˆí„°ë§/ë””ë²„ê¹…/ë¹„ìš© ì¶”ì â€ ê´€ì ì—ì„œ ê¹Šê²Œ íŒŒê³ ë“¤ê³ , ì‹¤ì œë¡œ ë°”ë¡œ ë¶™ì—¬ë³¼ ìˆ˜ ìˆëŠ” ì½”ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. (ë‘˜ ë‹¤ í•µì‹¬ í‚¤ì›Œë“œëŠ” ì´ì œ **OpenTelemetry(OTel)** ì…ë‹ˆë‹¤.) ([blog.langchain.com](https://blog.langchain.com/end-to-end-opentelemetry-langsmith?utm_source=openai))

---

## ğŸ”§ í•µì‹¬ ê°œë…
### 1) LLM Observabilityì—ì„œ â€œTraceâ€ê°€ ì˜ë¯¸í•˜ëŠ” ê²ƒ
LLM ì•±ì—ì„œ traceëŠ” ë³´í†µ ë‹¤ìŒì„ í¬í•¨í•©ë‹ˆë‹¤.

- **request(ìœ ì € ì…ë ¥) â†’ prompt êµ¬ì„± â†’ LLM call â†’ tool call/DB/RAG â†’ í›„ì²˜ë¦¬ â†’ ì‘ë‹µ**
- ê° ë‹¨ê³„ì˜ **latency**, **error**, **token usage**, **model name**, **retry** ì •ë³´
- ë‹¨ê³„ ê°„ ë¶€ëª¨-ìì‹ ê´€ê³„(íŠ¸ë¦¬)ê°€ ìˆì–´ â€œë³‘ëª©ì´ ì–´ë””ì¸ì§€â€ê°€ í•œëˆˆì— ë³´ì„

LangSmithëŠ” ì´ë¥¼ â€œRun(ìŠ¤íŒ¬ì— í•´ë‹¹)â€ íŠ¸ë¦¬ë¡œ ê°•í•˜ê²Œ ëª¨ë¸ë§í•˜ê³ , ë¹„ìš©/í† í°ì„ íŠ¸ë¦¬ ìƒì—ì„œ ì§‘ê³„í•˜ëŠ” UXê°€ íƒ„íƒ„í•©ë‹ˆë‹¤. ([docs.langchain.com](https://docs.langchain.com/langsmith/cost-tracking?utm_source=openai))

### 2) OpenTelemetry(OTel)ê°€ ì™œ ê°‘ìê¸° ì¤‘ìš”í•´ì¡Œë‚˜
ê³¼ê±°ì—” íˆ´ë§ˆë‹¤ ê³ ìœ  SDKë¡œë§Œ ê³„ì¸¡í•˜ëŠ” ê²½ìš°ê°€ ë§ì•˜ëŠ”ë°, LLM ì•±ì´ ì»¤ì§€ë©´ ë‹¤ìŒ ë¬¸ì œê°€ ìƒê¹ë‹ˆë‹¤.

- ì„œë¹„ìŠ¤ê°€ ì—¬ëŸ¬ ê°œë¡œ ìª¼ê°œì§€ë©´ì„œ **ë¶„ì‚° íŠ¸ë ˆì´ì‹±**ì´ í•„ìš”
- LLM ë‹¨ê³„ë§Œì´ ì•„ë‹ˆë¼ **API Gateway, worker, DB, queue**ê¹Œì§€ ê°™ì€ Trace IDë¡œ ì—®ê³  ì‹¶ìŒ
- íŠ¹ì • ë²¤ë”ì— ì¢…ì†ë˜ì§€ ì•Šê³  exporterë§Œ ë°”ê¿”ì„œ ì´ê´€í•˜ê³  ì‹¶ìŒ

LangSmithëŠ” â€œLangChain/LangGraphâ€ ìƒíƒœê³„ì— ê°•ì ì´ ìˆê³ , 2025ë…„ì—ëŠ” **SDK ë ˆë²¨ end-to-end OTel ì§€ì›**ì„ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤(ë„¤ì´í‹°ë¸Œ í¬ë§· ëŒ€ë¹„ ì•½ê°„ì˜ overheadê°€ ìˆì„ ìˆ˜ ìˆë‹¤ê³ ë„ ëª…ì‹œ). ([blog.langchain.com](https://blog.langchain.com/end-to-end-opentelemetry-langsmith?utm_source=openai))  
Langfuseë„ 2025ë…„ë¶€í„° **OTel span ingest**ë¥¼ ì „ë©´ìœ¼ë¡œ ë‚´ì„¸ì›Œ ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ ì—°ê²°ì„ í™•ì¥í–ˆìŠµë‹ˆë‹¤. ([python-sdk-v2.docs-snapshot.langfuse.com](https://python-sdk-v2.docs-snapshot.langfuse.com/changelog/2025-02-14-opentelemetry-tracing/?utm_source=openai))

### 3) ë¹„ìš© ì¶”ì ì˜ ë³¸ì§ˆ: â€œí† í° ì§‘ê³„â€ê°€ ì•„ë‹ˆë¼ â€œì‹¤í–‰ ê²½ë¡œ ë¹„ìš© íšŒê³„â€
í˜„ì¥ì—ì„œ ë¹„ìš© ì¶”ì ì´ ì‹¤íŒ¨í•˜ëŠ” íŒ¨í„´ì€ ëŒ€ê°œ ì´ê²ë‹ˆë‹¤.

- â€œLLM í˜¸ì¶œ ë¹„ìš©â€ë§Œ ë³´ê³ , **tool call / retrieval / rerank / embedding / retry** ë¹„ìš©ì€ ëˆ„ë½
- trace íŠ¸ë¦¬ì˜ ìì‹ ìŠ¤íŒ¬ì— thread/session ë©”íƒ€ë°ì´í„°ê°€ ë¹ ì ¸ì„œ **ëŒ€í™” ë‹¨ìœ„ ì§‘ê³„ê°€ í‹€ì–´ì§**
- reasoning ëª¨ë¸(o1 ê³„ì—´ ë“±)ì²˜ëŸ¼ **output tokenì´ ë³µì¡**í•œ ê²½ìš°, ë¬¸ìì—´ë¡œ í† í°ì„ ì—­ì¶”ì •í•˜ë©´ ë¹„ìš©ì´ ì–´ê¸‹ë‚¨

LangSmithëŠ” major providerì— ëŒ€í•´ í† í°/ë¹„ìš©ì„ ìë™ ê¸°ë¡í•˜ê³ , **custom cost**ë„ run ë‹¨ìœ„ë¡œ ë„£ì–´ â€œë‹¨ì¼ ë¹„ìš© ë·°â€ë¥¼ ë§Œë“¤ ìˆ˜ ìˆê²Œ ê°€ì´ë“œí•©ë‹ˆë‹¤. ë˜í•œ thread ë©”íƒ€ë°ì´í„° ëˆ„ë½ ì‹œ ì§‘ê³„ê°€ ê¹¨ì§ˆ ìˆ˜ ìˆìŒì„ ë¬¸ì„œì—ì„œ ëª…í™•íˆ ê²½ê³ í•©ë‹ˆë‹¤. ([docs.langchain.com](https://docs.langchain.com/langsmith/cost-tracking?utm_source=openai))  
Langfuse ìª½ì€ OpenAI o1 ê³„ì—´ì²˜ëŸ¼ â€œtoken counts ì—†ì´ëŠ” ë¹„ìš© ì¶”ì • ë¶ˆê°€â€ ì¼€ì´ìŠ¤ë¥¼ ëª…í™•íˆ ì–¸ê¸‰í–ˆê³ , wrapper/integrationì„ ì“°ì§€ ì•Šìœ¼ë©´ usageë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë„£ì–´ì•¼ í•˜ëŠ” ì‚¬ë¡€ê°€ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ë“±ì¥í•©ë‹ˆë‹¤. ([python-sdk-v2.docs-snapshot.langfuse.com](https://python-sdk-v2.docs-snapshot.langfuse.com/changelog/2024-09-13-openai-o1-models/?utm_source=openai))

---

## ğŸ’» ì‹¤ì „ ì½”ë“œ
ì•„ë˜ ì˜ˆì‹œëŠ” â€œìµœì†Œ ì½”ë“œ ë³€ê²½ìœ¼ë¡œâ€ **OTelë¡œ ê³„ì¸¡í•˜ê³ **, â€œLLM í˜¸ì¶œ + tool ë¹„ìš©â€ì„ ê°™ì€ traceì— ë¬¶ì–´ **ë””ë²„ê¹…/ë¹„ìš© ì¶”ì **ê¹Œì§€ ê°€ëŠ¥í•˜ê²Œ ë§Œë“œëŠ” í˜•íƒœì— ì§‘ì¤‘í•©ë‹ˆë‹¤.

### ì˜ˆì œ 1) LangSmith: OTel ê¸°ë°˜ tracing + ì»¤ìŠ¤í…€ ë¹„ìš©(íˆ´ í˜¸ì¶œ) ì¶”ê°€
```python
# python
"""
ëª©í‘œ:
- LangSmithë¡œ OpenTelemetry ê¸°ë°˜ tracing í™œì„±í™”
- LangChain ì‹¤í–‰ì„ traceë¡œ ìˆ˜ì§‘
- (ì¤‘ìš”) LLM ë¹„ìš© ì™¸ì— 'tool ë¹„ìš©'ì„ custom costë¡œ ê°™ì´ ê¸°ë¡í•˜ëŠ” íŒ¨í„´ ì œì‹œ

ì‚¬ì „ ì¤€ë¹„:
pip install "langsmith[otel]" langchain langchain-openai

í™˜ê²½ë³€ìˆ˜:
LANGSMITH_API_KEY=...
LANGSMITH_TRACING=true
LANGSMITH_OTEL_ENABLED=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
"""

import os
import time
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# LangSmith/LangChainì€ envë¡œ tracingì„ ì¼œë©´ ìë™ ê³„ì¸¡ì´ ë“¤ì–´ê°„ë‹¤. ([blog.langchain.com](https://blog.langchain.com/end-to-end-opentelemetry-langsmith?utm_source=openai))

def expensive_tool_call(query: str) -> str:
    # ì˜ˆ: ì™¸ë¶€ ê²€ìƒ‰ API, rerank, í¬ë¡¤ë§ ë“± LLM ì™¸ë¶€ ë¹„ìš©ì´ ë°œìƒí•˜ëŠ” ì»´í¬ë„ŒíŠ¸
    time.sleep(0.2)
    return f"[tool-result for {query}]"

def main():
    prompt = ChatPromptTemplate.from_template(
        "Use the tool result to answer.\nTool result: {tool}\nQuestion: {q}"
    )
    model = ChatOpenAI(model="gpt-4o-mini")  # ì˜ˆì‹œ

    # 1) tool í˜¸ì¶œ
    tool_result = expensive_tool_call("langsmith vs langfuse")

    # 2) LLM í˜¸ì¶œ (LangChain ì‹¤í–‰ì€ traceë¡œ ìˆ˜ì§‘)
    chain = prompt | model
    out = chain.invoke({"tool": tool_result, "q": "ë¹„ìš© ì¶”ì ì—ì„œ ê°€ì¥ í”í•œ í•¨ì •ì€?"})
    print(out.content)

    # 3) "íˆ´ ë¹„ìš©"ì„ ê°™ì€ traceì— ë¶™ì´ë ¤ë©´:
    #    - LangSmithëŠ” run ë‹¨ìœ„ë¡œ custom costë¥¼ ì œì¶œí•  ìˆ˜ ìˆë„ë¡ ê°€ì´ë“œí•œë‹¤. ([docs.langchain.com](https://docs.langchain.com/langsmith/cost-tracking?utm_source=openai))
    #    - ì—¬ê¸°ì„œëŠ” ê°œë… ì˜ˆì‹œë¡œë§Œ ë‚¨ê¸´ë‹¤(ì‹¤ì œë¡  langsmith Clientë¡œ run_idì— costë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í˜•íƒœë¡œ êµ¬í˜„).
    #
    # í•µì‹¬: LLM token ë¹„ìš©ë§Œ ë³´ì§€ ë§ê³  tool/retrieval/retry ë¹„ìš©ì„ ë°˜ë“œì‹œ ê°™ì€ execution treeì— í•©ì‚°í•´ì•¼
    #       "ì™œ ë¹„ì‹¸ì¡ŒëŠ”ì§€" ë””ë²„ê¹…ì´ ëœë‹¤.

if __name__ == "__main__":
    main()
```

### ì˜ˆì œ 2) Langfuse: OTel ì² í•™(í‘œì¤€ ì»¨í…ìŠ¤íŠ¸ ì „íŒŒ) ê¸°ë°˜ìœ¼ë¡œ â€œëˆ„ë½ ì—†ëŠ” ê³„ì¸¡â€ ë§Œë“¤ê¸°
LangfuseëŠ” 2025ë…„ë¶€í„° OTel ê¸°ë°˜ SDK ë°©í–¥ì„ ê°•í•˜ê²Œ ë°€ê³  ìˆê³ , OTelì˜ ì¥ì (í‘œì¤€ context propagation, ì„œë“œíŒŒí‹° ê³„ì¸¡ê³¼ì˜ ê²°í•©)ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ([github.com](https://github.com/orgs/langfuse/discussions/6993?utm_source=openai))

ì•„ë˜ëŠ” â€œí•µì‹¬ ì•„ì´ë””ì–´â€ ì˜ˆì‹œì…ë‹ˆë‹¤.

```python
# python
"""
ëª©í‘œ:
- OpenTelemetry ì»¨í…ìŠ¤íŠ¸ ì „íŒŒê°€ ë˜ëŠ” êµ¬ì¡°ë¡œ spanì„ ìª¼ê°œì„œ
  LLM step / tool stepì„ í•œ traceë¡œ ë¬¶ëŠ” íŒ¨í„´ì„ ë§Œë“ ë‹¤.
- (ì¤‘ìš”) token/costê°€ ìë™ìœ¼ë¡œ ì•ˆ ì¡íˆëŠ” ì¼€ì´ìŠ¤ê°€ ìˆìœ¼ë¯€ë¡œ,
  wrapper/í†µí•©ì„ ì“°ê±°ë‚˜ usageë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë„£ëŠ” ì „ëµì„ ì¤€ë¹„í•œë‹¤. ([github.com](https://github.com/orgs/langfuse/discussions/6999?utm_source=openai))
"""

from opentelemetry import trace

tracer = trace.get_tracer("llm-app")

def tool_step():
    with tracer.start_as_current_span("tool:search") as span:
        # ì—¬ê¸°ì— tool latency, error, cost ë“±ì„ attributeë¡œ ê¸°ë¡
        span.set_attribute("tool.name", "search-api")
        span.set_attribute("tool.cost_usd", 0.002)  # ì˜ˆì‹œ: tool ë¹„ìš©ì„ ëª…ì‹œ
        return "tool-result"

def llm_step(prompt: str):
    with tracer.start_as_current_span("llm:generate") as span:
        span.set_attribute("gen_ai.system", "openai")  # í‘œì¤€/ì¤€í‘œì¤€ ì†ì„± ê³„ì—´
        span.set_attribute("llm.model_name", "gpt-4o-mini")
        # ì£¼ì˜: ëª¨ë¸/SDK ì¡°í•©ì— ë”°ë¼ token usageê°€ ìë™ ìˆ˜ì§‘ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ ([github.com](https://github.com/orgs/langfuse/discussions/6999?utm_source=openai))
        # ê°€ëŠ¥í•˜ë©´ Langfuse wrapper/integration(LangChain, LlamaIndex, LiteLLM ë“±)ì„ í™œìš©í•˜ê±°ë‚˜,
        # usageë¥¼ ëª…ì‹œì ìœ¼ë¡œ ê¸°ë¡í•˜ëŠ” ê²½ë¡œë¥¼ ë§ˆë ¨í•´ì•¼ í•œë‹¤.
        return "answer"

def main():
    with tracer.start_as_current_span("request") as root:
        tool = tool_step()
        ans = llm_step(f"tool={tool}")
        print(ans)

if __name__ == "__main__":
    main()
```

---

## âš¡ ì‹¤ì „ íŒ
### 1) â€œOTel ì±„íƒâ€ì€ ê¸°ëŠ¥ì´ ì•„ë‹ˆë¼ ì¡°ì§ ì•„í‚¤í…ì²˜ ì„ íƒì´ë‹¤
- ì„œë¹„ìŠ¤ê°€ 1ê°œê³  Python ë‹¨ì¼ ëŸ°íƒ€ì„ì´ë©´ â€œë²¤ë” SDK ì§ê²°â€ë„ ë¹ ë¦…ë‹ˆë‹¤.
- í•˜ì§€ë§Œ API/worker/queueë¡œ ê°ˆë¼ì§€ê³ , ì¸í”„ë¼ ê´€ì¸¡(HTTP, DB)ê¹Œì§€ í•©ì¹˜ë ¤ë©´ OTelì´ ì‚¬ì‹¤ìƒ ì •ë‹µì…ë‹ˆë‹¤. LangSmithë„ OTelì„ â€œìŠ¤íƒ ì „ì²´ë¥¼ í†µí•© ê´€ì¸¡â€í•˜ëŠ” ê´€ì ì—ì„œ ì„¤ëª…í•©ë‹ˆë‹¤. ([blog.langchain.com](https://blog.langchain.com/end-to-end-opentelemetry-langsmith?utm_source=openai))

### 2) ë¹„ìš© ì¶”ì ì˜ í•¨ì •: â€œtokenì´ ì•„ë‹ˆë¼ metadataê°€ ê¹¨ì ¸ì„œ ì§‘ê³„ê°€ í‹€ì–´ì§€ëŠ”â€ ì¼€ì´ìŠ¤
LangSmith ë¬¸ì„œì—ì„œ íŠ¹íˆ ì‹¤ë¬´ì ì¸ í¬ì¸íŠ¸ëŠ” **thread/session ë©”íƒ€ë°ì´í„°**ì…ë‹ˆë‹¤. ìì‹ runì— session/thread ë©”íƒ€ë°ì´í„°ê°€ ëˆ„ë½ë˜ë©´ â€œëŒ€í™” ë‹¨ìœ„â€ ì§‘ê³„ê°€ ì–´ê¸‹ë‚  ìˆ˜ ìˆë‹¤ê³  ëª» ë°•ìŠµë‹ˆë‹¤. ([docs.langchain.com](https://docs.langchain.com/langsmith/cost-tracking?utm_source=openai))  
â†’ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” â€œtraceëŠ” ì°íˆëŠ”ë° ë¹„ìš© ëŒ€ì‹œë³´ë“œê°€ ì´ìƒí•¨â€ì˜ 1ìˆœìœ„ ì›ì¸ì´ ë©ë‹ˆë‹¤.

### 3) reasoning ëª¨ë¸(o1 ê³„ì—´ ë“±)ì€ â€œusage ë¯¸ì œê³µ ì‹œ ë¹„ìš© ì¶”ì • ë¶ˆê°€â€ë¥¼ ì „ì œë¡œ ì„¤ê³„í•˜ë¼
LangfuseëŠ” o1 ê³„ì—´ì—ì„œ **token counts ì—†ì´ëŠ” cost inferenceê°€ ë¶ˆê°€ëŠ¥**í•˜ë‹¤ê³  ëª…ì‹œí•©ë‹ˆë‹¤. ([python-sdk-v2.docs-snapshot.langfuse.com](https://python-sdk-v2.docs-snapshot.langfuse.com/changelog/2024-09-13-openai-o1-models/?utm_source=openai))  
â†’ ê²°ë¡ : wrapper/integrationì„ ì“°ë“ , ì‘ë‹µì—ì„œ usageë¥¼ íŒŒì‹±í•´ ë„£ë“ , â€œusageë¥¼ í™•ë³´í•˜ëŠ” ê²½ë¡œâ€ê°€ ì„¤ê³„ì— í¬í•¨ë¼ì•¼ í•©ë‹ˆë‹¤.

### 4) ê°€ê²© ëª¨ë¸ ë¹„êµëŠ” â€œê³¼ê¸ˆ ë‹¨ìœ„â€ë¥¼ ë¨¼ì € ë§ì¶°ì•¼ í•œë‹¤
- LangSmith: seat + trace ê³¼ê¸ˆ(ë³´ì¡´ ê¸°ê°„ì— ë”°ë¼ base/extended) êµ¬ì¡°ê°€ ëª…í™•í•©ë‹ˆë‹¤. ([langchain.com](https://www.langchain.com/pricing?utm_source=openai))  
- Langfuse: CloudëŠ” â€œunits/eventsâ€ ê¸°ë°˜ í‹°ì–´ê°€ ì–¸ê¸‰ë˜ë©°(ìë£Œë§ˆë‹¤ ìˆ˜ì¹˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ê³µì‹ í™•ì¸ ê¶Œì¥), self-host ì˜µì…˜ì´ ê°•ì ìœ¼ë¡œ ìì£¼ ê±°ë¡ ë©ë‹ˆë‹¤. ([linkedin.com](https://www.linkedin.com/posts/langfuse_recently-we-announced-open-sourcing-of-all-activity-7343300378274226176-TDPs?utm_source=openai))  
â†’ **â€œìš”ì²­ 1ê±´ë‹¹ í‰ê·  ìŠ¤íŒ¬ ìˆ˜(=trace depth)â€**ë¥¼ ë¨¼ì € ì‚°ì •í•˜ì§€ ì•Šìœ¼ë©´, ì›” ë¹„ìš© ë¹„êµëŠ” ê±°ì˜ í•­ìƒ í‹€ë¦½ë‹ˆë‹¤.

---

## ğŸš€ ë§ˆë¬´ë¦¬
2026ë…„ 2ì›” ì‹œì ì—ì„œ LLM ì•± ëª¨ë‹ˆí„°ë§ì˜ ì¤‘ì‹¬ì¶•ì€ í™•ì‹¤íˆ **Trace(íŠ¸ë¦¬) + ë¹„ìš©(í† í°/íˆ´) + ë””ë²„ê¹…(ì¬í˜„ ê°€ëŠ¥í•œ ì»¨í…ìŠ¤íŠ¸)**ë¡œ ìë¦¬ ì¡ì•˜ìŠµë‹ˆë‹¤. LangSmithëŠ” LangChain ìƒíƒœê³„ì™€ ì´˜ì´˜í•œ UI/ê°€ì´ë“œ(íŠ¹íˆ ë¹„ìš©/ë©”íƒ€ë°ì´í„° ì§‘ê³„)ì—ì„œ ê°•ì ì„ ë³´ì´ê³ , OTelë„ end-to-endë¡œ ëŒì–´ì•ˆëŠ” ë°©í–¥ì„ ë¶„ëª…íˆ í–ˆìŠµë‹ˆë‹¤. ([blog.langchain.com](https://blog.langchain.com/end-to-end-opentelemetry-langsmith?utm_source=openai))  
LangfuseëŠ” OTel í‘œì¤€ì„ ì ê·¹ í™œìš©í•´ ì–¸ì–´/í”„ë ˆì„ì›Œí¬ í™•ì¥ì„±ê³¼ self-host ì˜µì…˜ì„ ë¬´ê¸°ë¡œ ê°€ì ¸ê°€ë©°, íŠ¹íˆ â€œusage ë¯¸ì œê³µ ì‹œ ë¹„ìš© ì¶”ì • ì‹¤íŒ¨â€ ê°™ì€ í˜„ì‹¤ì ì¸ í¬ì¸íŠ¸ë¥¼ ì¼€ì´ìŠ¤ë¡œ ì¶•ì í•´ ì™”ìŠµë‹ˆë‹¤. ([github.com](https://github.com/orgs/langfuse/discussions/6993?utm_source=openai))

ë‹¤ìŒ í•™ìŠµ ì¶”ì²œì€ ë‘ ê°€ì§€ì…ë‹ˆë‹¤.
1) OpenTelemetry context propagationì„ â€œì„œë¹„ìŠ¤ ê²½ê³„(HTTP/queue)â€ê¹Œì§€ í™•ì¥í•´ end-to-end traceë¥¼ ì™„ì„±í•˜ê¸°  
2) ë¹„ìš© ì¶”ì ì„ LLM í˜¸ì¶œì—ë§Œ ë‘ì§€ ë§ê³ , tool/retrieval/rerank/retryë¥¼ **ê°™ì€ execution treeì— íšŒê³„ ì²˜ë¦¬**í•˜ëŠ” êµ¬ì¡°ë¡œ ë¦¬íŒ©í„°ë§í•˜ê¸°

ì›í•˜ì‹œë©´, ë‹¤ìŒ ë‹¨ê³„ë¡œ **â€œê°™ì€ ì•±ì„ LangSmith/Langfuse ë‘˜ ë‹¤ë¡œ ë™ì‹œì— exportí•˜ëŠ” OTel íŒŒì´í”„ë¼ì¸ ì„¤ê³„(Collector êµ¬ì„±)â€**ê¹Œì§€ ì´ì–´ì„œ íŠœí† ë¦¬ì–¼ í˜•íƒœë¡œ ì •ë¦¬í•´ë“œë¦´ê²Œìš”.
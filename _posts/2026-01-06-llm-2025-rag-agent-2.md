---
title: "LLMì´ â€œì°¾ì•„ë³´ê³ (ê²€ìƒ‰) â†’ íŒë‹¨í•˜ê³ (ê³„íš) â†’ ë‹µí•œë‹¤(ìƒì„±)â€ê¹Œì§€ í•˜ëŠ” 2025 RAG Agent êµ¬í˜„ íŠœí† ë¦¬ì–¼"
date: 2026-01-06 02:16:22 +0900
categories: [AI, Tutorial]
tags: [ai, tutorial, trend, 2026-01]
---

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7990TVG7C7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7990TVG7C7');
</script>
## ë“¤ì–´ê°€ë©°
2025ë…„ì˜ RAGëŠ” ë” ì´ìƒ â€œvector DBì—ì„œ top-k ë½‘ì•„ í”„ë¡¬í”„íŠ¸ì— ë¶™ì´ëŠ”â€ ìˆ˜ì¤€ì—ì„œ ëë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì œí’ˆ/ìš´ì˜ í™˜ê²½ì—ì„œëŠ” (1) ì§ˆë¬¸ì´ ì• ë§¤í•˜ë©´ ì¬ì§ˆë¬¸í•˜ê±°ë‚˜, (2) ë‚´ë¶€ ë¬¸ì„œ/ì™¸ë¶€ ì›¹/DB/API ì¤‘ ì–´ë””ë¥¼ ë¨¼ì € ë³¼ì§€ ì„ íƒí•˜ê³ , (3) ì°¾ì€ ê·¼ê±°ê°€ ë¶€ì¡±í•˜ë©´ ì¬ê²€ìƒ‰Â·ì¬ë­í¬í•˜ê³ , (4) ìµœì¢… ë‹µë³€ì— **ê·¼ê±°(citation)ì™€ ì‹ ë¢°ë„**ê¹Œì§€ ë¶™ì—¬ì•¼ í•©ë‹ˆë‹¤. ì´ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” íŒ¨í„´ì´ ë°”ë¡œ **Agentic RAG**ì…ë‹ˆë‹¤. AWSë„ â€œAgentic RAGëŠ” multi-step, tool ì‚¬ìš©, ì ì‘í˜• íë¦„â€ìœ¼ë¡œ ì •ì˜í•˜ë©° ë‹¨ìˆœ QAë¥¼ ë„˜ì–´ì„ ë‹¤ê³  ëª…ì‹œí•©ë‹ˆë‹¤. ([aws.amazon.com](https://aws.amazon.com/blogs/machine-learning/create-an-agentic-rag-application-for-advanced-knowledge-discovery-with-llamaindex-and-mistral-in-amazon-bedrock/?utm_source=openai))

ë˜í•œ OpenAIëŠ” 2025ë…„ì— **Responses API + built-in tools(Web search / File search / MCP ë“±)**ë¡œ â€œíˆ´ ì‹¤í–‰ì„ ì¸í”„ë¼ì—ì„œ ìë™ ì²˜ë¦¬â€í•˜ëŠ” ë°©í–¥ì„ ê°•í™”í–ˆê³ , íŠ¹íˆ **File search**ëŠ” query optimizationÂ·metadata filteringÂ·rerankingì„ í¬í•¨í•´ RAG íŒŒì´í”„ë¼ì¸ì˜ ë²ˆê±°ë¡œìš´ ë¶€ë¶„ì„ í¬ê²Œ ì¤„ì˜€ìŠµë‹ˆë‹¤. ([developers.openai.com](https://developers.openai.com/tracks/building-agents?utm_source=openai))  
ì´ ê¸€ì—ì„œëŠ” â€œì§ì ‘ êµ¬í˜„(ì»¨íŠ¸ë¡¤ ê·¹ëŒ€í™”)â€ ê´€ì ì—ì„œ **RAG Agentì˜ ë‚´ë¶€ ì›ë¦¬**ë¥¼ í•´ë¶€í•˜ê³ , ê³§ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œë¡œ ëê¹Œì§€ ì—°ê²°í•©ë‹ˆë‹¤.

---

## ğŸ”§ í•µì‹¬ ê°œë…
### 1) RAGì˜ 3ê³„ì¸µ: Indexing / Retrieval / Generation
- **Indexing**: ë¬¸ì„œë¥¼ chunkë¡œ ìª¼ê°œê³  embeddingì„ ë§Œë“¤ì–´ vector storeì— ì €ì¥
- **Retrieval**: ì§ˆë¬¸ì„ embedding â†’ top-k ê²€ìƒ‰(+í•„ìš”ì‹œ hybrid, rerank)
- **Generation**: ê²€ìƒ‰ ê²°ê³¼ë¥¼ â€œê·¼ê±° ì»¨í…ìŠ¤íŠ¸â€ë¡œ ë„£ì–´ ë‹µë³€ ìƒì„±(ê°€ëŠ¥í•˜ë©´ citation í¬í•¨)

2025ë…„ ì‹¤ì „ì—ì„œ ì¤‘ìš”í•œ ê±´ Retrievalì´ â€œë‹¨ë°œâ€ì´ ì•„ë‹ˆë¼ëŠ” ì ì…ë‹ˆë‹¤. AgentëŠ” **ê²€ìƒ‰ ê²°ê³¼ì˜ í’ˆì§ˆì„ í‰ê°€**í•˜ê³  ë¶€ì¡±í•˜ë©´ ë‹¤ìŒ ì•¡ì…˜ì„ í•©ë‹ˆë‹¤(ì¬ì§ˆë¬¸, k ì¡°ì •, ë‹¤ë¥¸ ì†ŒìŠ¤ ì¡°íšŒ ë“±). AWSê°€ ë§í•˜ëŠ” â€œbreak down complex tasks / use external tools / adaptâ€ê°€ ì—¬ê¸°ì„œ ë‚˜ì˜µë‹ˆë‹¤. ([aws.amazon.com](https://aws.amazon.com/blogs/machine-learning/create-an-agentic-rag-application-for-advanced-knowledge-discovery-with-llamaindex-and-mistral-in-amazon-bedrock/?utm_source=openai))

### 2) Agentic RAGì˜ ì œì–´ ë£¨í”„(ì˜ì‚¬ê²°ì •)
Agentic RAGëŠ” ë³´í†µ ì•„ë˜ ë£¨í”„ë¥¼ ê°€ì§‘ë‹ˆë‹¤.

1. **Router(ì˜ì‚¬ê²°ì •)**: ì´ ì§ˆë¬¸ì€ â€œë‚´ë¶€ ë¬¸ì„œ ê²€ìƒ‰â€ì¸ê°€? â€œì›¹ ê²€ìƒ‰â€ì¸ê°€? â€œDB ì¡°íšŒâ€ì¸ê°€?
2. **Retriever(í–‰ë™)**: ì„ íƒí•œ ë„êµ¬/ë¦¬íŠ¸ë¦¬ë²„ ì‹¤í–‰
3. **Critic/Verifier(í‰ê°€)**: ê·¼ê±°ê°€ ì¶©ë¶„í•œê°€? ì¶œì²˜ê°€ ì‹ ë¢° ê°€ëŠ¥í•œê°€? ìƒì¶©í•˜ëŠ”ê°€?
4. **Synthesis(ìƒì„±)**: ë‹µë³€ + ê·¼ê±° + ì œí•œì‚¬í•­(ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³ )

OpenAIì˜ â€œbuilt-in toolsëŠ” ëª¨ë¸ì´ í˜¸ì¶œí•˜ë©´ ìë™ ì‹¤í–‰ë˜ê³  ê²°ê³¼ê°€ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€â€ëœë‹¤ëŠ” ì„¤ëª…ì€, ì´ ë£¨í”„ì˜ (2)ë¥¼ ë§¤ìš° ë‹¨ìˆœí™”í•©ë‹ˆë‹¤. ([developers.openai.com](https://developers.openai.com/tracks/building-agents?utm_source=openai))

### 3) 2025ë…„ RAGì—ì„œ ë‹¬ë¼ì§„ í¬ì¸íŠ¸: â€œê²€ìƒ‰ í’ˆì§ˆì´ ì œí’ˆ í’ˆì§ˆâ€
- chunking/metadata/rerankê°€ ì„±ëŠ¥ì„ ì¢Œìš°
- â€œtop-k=3â€ ê°™ì€ ê³ ì •ê°’ì€ ê¸ˆë°© í•œê³„
- ìš´ì˜ì—ì„œëŠ” **ê·¼ê±° ë…¸ì¶œ**(auditability)ì´ í•„ìˆ˜(íŠ¹íˆ B2B/ë‚´ë¶€ë¬¸ì„œ)
OpenAIëŠ” File searchì— query optimization, metadata filtering, rerankingì„ í¬í•¨í•œë‹¤ê³  ë°íˆë©° â€œê°•í•œ RAGë¥¼ ì¶”ê°€ íŠœë‹ ì—†ì´â€ êµ¬ì„±í•  ìˆ˜ ìˆë‹¤ê³  ì„¤ëª…í•©ë‹ˆë‹¤. ([openai.com](https://openai.com/index/new-tools-for-building-agents/?utm_source=openai))

---

## ğŸ’» ì‹¤ì „ ì½”ë“œ
ì•„ë˜ ì½”ë“œëŠ” **(A) ë¡œì»¬ ë²¡í„° ì¸ë±ìŠ¤(FAISS) ê¸°ë°˜ RAG** + **(B) ê°„ë‹¨í•œ Agent ë£¨í”„(ê²€ìƒ‰â†’í‰ê°€â†’ì¬ê²€ìƒ‰/ë‹µë³€)** ë¥¼ í•œ íŒŒì¼ì— êµ¬í˜„í•œ ì˜ˆì œì…ë‹ˆë‹¤.  
- ë¬¸ì„œ: ë¡œì»¬ í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì„ ì½ì–´ chunk â†’ embedding â†’ FAISS ì €ì¥  
- ì§ˆì˜: 1ì°¨ ê²€ìƒ‰ í›„ â€œê·¼ê±° ë¶€ì¡±â€ì´ë©´ kë¥¼ ëŠ˜ë ¤ ì¬ê²€ìƒ‰  
- ë‹µë³€: â€œê·¼ê±° ì™¸ ì¶”ì¸¡ ê¸ˆì§€â€ í”„ë¡¬í”„íŠ¸ + citation í˜•íƒœë¡œ source idë¥¼ ê°™ì´ ì¶œë ¥

```python
# rag_agent.py
# ì‹¤í–‰: pip install openai faiss-cpu tiktoken numpy
# í™˜ê²½ë³€ìˆ˜: OPENAI_API_KEY ì„¤ì •
from __future__ import annotations

import os
import glob
import numpy as np
import faiss
import tiktoken
from dataclasses import dataclass
from typing import List, Tuple, Dict

from openai import OpenAI

client = OpenAI()

EMBED_MODEL = "text-embedding-3-small"
GEN_MODEL = "gpt-4o-mini"

@dataclass
class Chunk:
    chunk_id: str
    text: str
    source: str

def chunk_text(text: str, source: str, chunk_tokens: int = 350, overlap: int = 50) -> List[Chunk]:
    """
    í† í° ê¸°ë°˜ chunking.
    - chunk_tokens/overlapì€ ë„ë©”ì¸ì— ë§ê²Œ íŠœë‹ í¬ì¸íŠ¸
    """
    enc = tiktoken.get_encoding("cl100k_base")
    toks = enc.encode(text)
    out = []
    step = max(1, chunk_tokens - overlap)

    for i in range(0, len(toks), step):
        piece = toks[i:i + chunk_tokens]
        if not piece:
            continue
        chunk_text = enc.decode(piece).strip()
        if len(chunk_text) < 20:
            continue
        out.append(Chunk(
            chunk_id=f"{source}::tok{i}",
            text=chunk_text,
            source=source
        ))
    return out

def embed(texts: List[str]) -> np.ndarray:
    """
    OpenAI embeddings -> float32 numpy matrix
    """
    resp = client.embeddings.create(model=EMBED_MODEL, input=texts)
    vecs = [d.embedding for d in resp.data]
    return np.array(vecs, dtype="float32")

class FaissStore:
    def __init__(self, dim: int):
        self.index = faiss.IndexFlatIP(dim)  # cosine ìœ ì‚¬ë„ë¥¼ ìœ„í•´ ë‚´ì  ì‚¬ìš©(ë²¡í„° ì •ê·œí™” ì „ì œ)
        self.chunks: List[Chunk] = []

    def add(self, vecs: np.ndarray, chunks: List[Chunk]):
        faiss.normalize_L2(vecs)
        self.index.add(vecs)
        self.chunks.extend(chunks)

    def search(self, query_vec: np.ndarray, k: int = 4) -> List[Tuple[Chunk, float]]:
        q = query_vec.astype("float32")
        faiss.normalize_L2(q)
        D, I = self.index.search(q, k)
        results = []
        for score, idx in zip(D[0].tolist(), I[0].tolist()):
            if idx == -1:
                continue
            results.append((self.chunks[idx], float(score)))
        return results

def build_store(doc_glob: str = "./docs/*.txt") -> FaissStore:
    files = sorted(glob.glob(doc_glob))
    if not files:
        raise RuntimeError("docs/*.txtì— ë¬¸ì„œë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")

    all_chunks: List[Chunk] = []
    for fp in files:
        with open(fp, "r", encoding="utf-8") as f:
            text = f.read()
        all_chunks.extend(chunk_text(text, source=os.path.basename(fp)))

    vecs = embed([c.text for c in all_chunks])
    store = FaissStore(dim=vecs.shape[1])
    store.add(vecs, all_chunks)
    return store

def judge_sufficiency(question: str, retrieved: List[Tuple[Chunk, float]]) -> bool:
    """
    íœ´ë¦¬ìŠ¤í‹± í‰ê°€:
    - ìƒìœ„ scoreê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ê·¼ê±° ë¶€ì¡±ìœ¼ë¡œ íŒë‹¨
    - ìš´ì˜ì—ì„œëŠ” ë³„ë„ reranker/LLM-criticì„ ë‘ëŠ” ê²Œ ì¼ë°˜ì 
    """
    if not retrieved:
        return False
    top_score = retrieved[0][1]
    return top_score >= 0.25  # ë°ì´í„°ì— ë”°ë¼ ì¡°ì •

def generate_answer(question: str, retrieved: List[Tuple[Chunk, float]]) -> str:
    context_lines = []
    for ch, score in retrieved:
        # citationì„ chunk_idë¡œ ë¶€ì—¬
        context_lines.append(f"[{ch.chunk_id} | score={score:.3f}]\n{ch.text}")

    system = (
        "You are a senior engineer. Answer ONLY using the provided CONTEXT.\n"
        "If the context is insufficient, say what is missing and ask a clarifying question.\n"
        "Include citations like [source_id] at the end of relevant sentences."
    )

    user = f"""QUESTION:
{question}

CONTEXT:
{'\n\n'.join(context_lines)}
"""

    resp = client.responses.create(
        model=GEN_MODEL,
        input=[
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ],
        temperature=0,
    )
    return resp.output_text

def rag_agent(question: str, store: FaissStore) -> str:
    """
    ë§¤ìš° ë‹¨ìˆœí™”ëœ Agent ë£¨í”„:
    - 1ì°¨ ê²€ìƒ‰(k=4) -> ë¶€ì¡±í•˜ë©´ k=10ìœ¼ë¡œ ì¬ê²€ìƒ‰ -> ë‹µë³€
    """
    qvec = embed([question])
    retrieved = store.search(qvec, k=4)

    if not judge_sufficiency(question, retrieved):
        # ì¬ê²€ìƒ‰(â€œë” ì°¾ì•„ë³´ê¸°â€ ì•¡ì…˜)
        retrieved = store.search(qvec, k=10)

    return generate_answer(question, retrieved)

if __name__ == "__main__":
    store = build_store("./docs/*.txt")
    q = "ìš°ë¦¬ ì„œë¹„ìŠ¤ì˜ ë°ì´í„° ë³´ê´€ ê¸°ê°„ê³¼ ì‚­ì œ ì •ì±…ì„ ìš”ì•½í•´ì¤˜."
    print(rag_agent(q, store))
```

í•µì‹¬ì€ â€œRAG + Agent ë£¨í”„â€ë¥¼ ë¶„ë¦¬í•´ì„œ ìƒê°í•˜ëŠ” ê²ë‹ˆë‹¤. OpenAIê°€ ë§í•˜ëŠ” ê²ƒì²˜ëŸ¼ built-in **file search**ë¥¼ ì“°ë©´ retrieval(ì¿¼ë¦¬ ìµœì í™”/ë¦¬ë­í¬ í¬í•¨)ì„ í”Œë«í¼ì— ìœ„ì„í•  ìˆ˜ ìˆê³  ([openai.com](https://openai.com/index/new-tools-for-building-agents/?utm_source=openai)), ìœ„ ì½”ë“œì²˜ëŸ¼ ì§ì ‘ êµ¬í˜„í•˜ë©´ â€œë‚´ê°€ ì›í•˜ëŠ” chunking/ë©”íƒ€ë°ì´í„°/í‰ê°€ê¸°ì¤€â€ì„ ëê¹Œì§€ ì»¨íŠ¸ë¡¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## âš¡ ì‹¤ì „ íŒ
- **Chunkingì€ â€˜ê· ì¼ ê¸¸ì´â€™ë³´ë‹¤ â€˜ì˜ë¯¸ ë‹¨ìœ„â€™ê°€ ì´ê¹ë‹ˆë‹¤.** í† í° ê¸°ì¤€ chunkingì€ ì‹œì‘ì ì¼ ë¿ì´ê³ , ì œëª©/ì„¹ì…˜/í‘œ/ì½”ë“œë¸”ë¡ ê²½ê³„ë¥¼ ì‚´ë¦¬ëŠ” â€œsemantic chunkingâ€ì´ ê²€ìƒ‰ í’ˆì§ˆì„ í¬ê²Œ ì˜¬ë¦½ë‹ˆë‹¤(íŠ¹íˆ ê¸°ìˆ  ë¬¸ì„œ).
- **Hybrid search + rerankë¥¼ ê³ ë ¤í•˜ì„¸ìš”.** vector ìœ ì‚¬ë„ë§Œ ì“°ë©´ â€œì •í™•í•œ í‚¤ì›Œë“œ(ë²„ì „/ì—ëŸ¬ì½”ë“œ/ì„¤ì •í‚¤)â€ë¥¼ ë†“ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. BM25+vector í˜¼í•© í›„ rerankerë¡œ ì •ë ¬í•˜ëŠ” ì¡°í•©ì´ ì•ˆì •ì ì…ë‹ˆë‹¤.
- **Agentì˜ â€˜í‰ê°€ ë‹¨ê³„â€™ë¥¼ ì½”ë“œë¡œ ë¶„ë¦¬**í•˜ì„¸ìš”. ìœ„ ì˜ˆì œëŠ” score íœ´ë¦¬ìŠ¤í‹±ì´ì§€ë§Œ, ìš´ì˜ì—ì„œëŠ” (a) LLM-critic, (b) ê·œì¹™ ê¸°ë°˜(í•„ìˆ˜ ì„¹ì…˜/í‚¤ì›Œë“œ ì¡´ì¬), (c) ì¶©ëŒ ê°ì§€(ì„œë¡œ ë‹¤ë¥¸ ê·¼ê±°) ë“±ì„ ì¡°í•©í•©ë‹ˆë‹¤.
- **CitationsëŠ” ê¸°ëŠ¥ì´ ì•„ë‹ˆë¼ ì•ˆì „ì¥ì¹˜**ì…ë‹ˆë‹¤. â€œë‹µë³€ ë¬¸ì¥ â†” ê·¼ê±° chunkâ€ ë§í¬ê°€ ìˆì–´ì•¼ ë””ë²„ê¹…ì´ ë©ë‹ˆë‹¤. OpenAIë„ File searchë¥¼ RAG íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬ ë„êµ¬ë¡œ ê°•ì¡°í•˜ë©´ì„œ ë¹ ë¥´ê³  ì •í™•í•œ ê²€ìƒ‰ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ([openai.com](https://openai.com/index/new-tools-for-building-agents/?utm_source=openai))
- **íˆ´ì„ ëŠ˜ë¦´ìˆ˜ë¡ ê´€ì¸¡ ê°€ëŠ¥ì„±(Observability)ì´ ë¨¼ì €**ì…ë‹ˆë‹¤. Agentic RAGëŠ” multi-stepì´ ê¸°ë³¸ì´ë¯€ë¡œ, ê° ìŠ¤í…(ì¿¼ë¦¬ ë³€í™˜/ê²€ìƒ‰/ë¦¬ë­í¬/ìƒì„±)ì˜ ë¡œê·¸ì™€ ë¹„ìš©, latencyë¥¼ ë¶„ë¦¬í•´ì„œ ìˆ˜ì§‘í•˜ì„¸ìš”.

---

## ğŸš€ ë§ˆë¬´ë¦¬
2025ë…„ì˜ â€œRAG Agent êµ¬í˜„â€ì€ ê²°êµ­ **(1) Retrieval í’ˆì§ˆì„ ì˜¬ë¦¬ëŠ” ì—”ì§€ë‹ˆì–´ë§**ê³¼ **(2) Agent ë£¨í”„ë¡œ ì˜ì‚¬ê²°ì •ì„ ìë™í™”**í•˜ëŠ” ë¬¸ì œë¡œ ì •ë¦¬ë©ë‹ˆë‹¤. OpenAIì˜ built-in tools(íŠ¹íˆ File search)ëŠ” RAGì˜ ë³µì¡í•œ ë‹¨ê³„ë¥¼ í¬ê²Œ ì¤„ì—¬ì£¼ê³  ([developers.openai.com](https://developers.openai.com/tracks/building-agents?utm_source=openai)), ë°˜ëŒ€ë¡œ ì§ì ‘ êµ¬í˜„ì€ ë„ë©”ì¸ ìµœì í™”(ë©”íƒ€ë°ì´í„°/í‰ê°€/ë³´ì•ˆ/ë¹„ìš©)ì—ì„œ ê°•í•©ë‹ˆë‹¤.

ë‹¤ìŒ í•™ìŠµìœ¼ë¡œëŠ”:
- OpenAI **Responses API + File search** ê¸°ë°˜ â€œmanaged RAGâ€ íŒ¨í„´ (ë¹ ë¥¸ ì œí’ˆí™”) ([openai.com](https://openai.com/index/new-tools-for-building-agents/?utm_source=openai))
- LlamaIndexì˜ **agentic strategies/workflows**ë¡œ â€œroutingÂ·query transformationÂ·tool orchestrationâ€ í™•ì¥ ([docs.llamaindex.ai](https://docs.llamaindex.ai/en/stable/optimizing/agentic_strategies/agentic_strategies/?utm_source=openai))

ì›í•˜ì‹œë©´, ìœ„ ì½”ë“œì— **(a) metadata í•„í„°ë§, (b) reranker ì¶”ê°€, (c) ëŒ€í™” ë©”ëª¨ë¦¬(ì„¸ì…˜/ì¥ê¸°) ê³„ì¸µ**, (d) ì›¹ ê²€ìƒ‰ íˆ´ê¹Œì§€ ë¶™ì—¬ì„œ â€œì§„ì§œ Agentic RAGâ€ í˜•íƒœë¡œ í™•ì¥í•œ ë²„ì „ë„ ì´ì–´ì„œ ì‘ì„±í•´ë“œë¦´ê²Œìš”.
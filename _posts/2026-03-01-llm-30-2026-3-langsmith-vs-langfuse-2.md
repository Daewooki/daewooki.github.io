---
title: "LLM ì•±ì´ â€œì™œ ì´ìƒí•˜ê²Œâ€ ë™ì‘í•˜ëŠ”ì§€ 30ë¶„ ì•ˆì— ì¡ì•„ë‚´ëŠ” ê´€ì¸¡ì„±: 2026ë…„ 3ì›” LangSmith vs Langfuse ì‹¬ì¸µ ë¶„ì„ (ë””ë²„ê¹…Â·ë¹„ìš©Â·ì¶”ì )"
date: 2026-03-01 02:58:29 +0900
categories: [AI, MLOps]
tags: [ai, mlops, trend, 2026-03]
---

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7990TVG7C7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7990TVG7C7');
</script>

## ë“¤ì–´ê°€ë©°
2026ë…„ 3ì›” ê¸°ì¤€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ìš´ì˜ì˜ ë³¸ì§ˆì€ â€œëª¨ë¸ ì„±ëŠ¥â€ì´ ì•„ë‹ˆë¼ â€œì‹œìŠ¤í…œ ì„±ëŠ¥â€ì…ë‹ˆë‹¤. ê°™ì€ promptë¼ë„ **ì»¨í…ìŠ¤íŠ¸(íˆ´ í˜¸ì¶œ, RAG ê²€ìƒ‰ ê²°ê³¼, ì¬ì‹œë„, ë¼ìš°íŒ…, ìºì‹œ, ëª¨ë¸ ë²„ì „)**ì— ë”°ë¼ ê²°ê³¼ê°€ ì¶œë ì´ê³ , ì¥ì• ëŠ” ëŒ€ê°œ ì½”ë“œê°€ ì•„ë‹ˆë¼ **ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜(Agent graph)ì™€ ì™¸ë¶€ ì˜ì¡´ì„±**ì—ì„œ í„°ì§‘ë‹ˆë‹¤. ê·¸ë˜ì„œ í”„ë¡œë•ì…˜ì—ì„œ í•„ìš”í•œ ê±´ ë¡œê·¸ê°€ ì•„ë‹ˆë¼ **trace ì¤‘ì‹¬ì˜ observability**ì…ë‹ˆë‹¤.

ì´ë•Œ ëŒ€í‘œ ì„ íƒì§€ê°€ LangSmith(ìƒìš© SaaS ì¤‘ì‹¬)ì™€ Langfuse(ì˜¤í”ˆì†ŒìŠ¤/ìì²´ í˜¸ìŠ¤íŒ… ì¹œí™”)ì¸ë°, ë‘˜ ë‹¤ â€œtrace ë³´ê¸°â€ë¥¼ ë„˜ì–´ì„œ **ë””ë²„ê¹…(ì›ì¸ ì¶”ì )**, **ë¹„ìš©/í† í° ì¶”ì (ì¬ë¬´ ê´€ì ì˜ SLO)**, ê·¸ë¦¬ê³  **í‘œì¤€í™”(OpenTelemetry)**ë¡œ ê°€ê³  ìˆë‹¤ëŠ” ì ì´ í•µì‹¬ ë³€í™”ì…ë‹ˆë‹¤. LangSmithëŠ” SDK ë‹¨ê³„ê¹Œì§€ end-to-end OpenTelemetry ì§€ì›ì„ í™•ì¥í–ˆê³ (2025-03), ë¹„ìš© ì¶”ì  ëŒ€ì‹œë³´ë“œë¥¼ ê³µì‹ ë¬¸ì„œë¡œ ì²´ê³„í™”í–ˆìŠµë‹ˆë‹¤. ([blog.langchain.com](https://blog.langchain.com/end-to-end-opentelemetry-langsmith?utm_source=openai)) LangfuseëŠ” JS ìƒíƒœê³„ì—ì„œ OpenTelemetry ê¸°ë°˜ SDK v4ë¡œ ì¬êµ¬ì„±í•˜ë©°(2025-08 ê³µì§€), OTEL export ë„êµ¬(@langfuse/otel)ê¹Œì§€ ì œê³µí•´ â€œí‘œì¤€ íŒŒì´í”„ë¼ì¸â€ì— ì˜¬ë¼íƒ”ìŠµë‹ˆë‹¤. ([github.com](https://github.com/orgs/langfuse/discussions/8403?utm_source=openai))

---

## ğŸ”§ í•µì‹¬ ê°œë…
### 1) Trace / Span / Context propagation
- **Trace**: â€œì‚¬ìš©ì ìš”ì²­ 1ê±´â€ì˜ end-to-end ì‹¤í–‰ ë‹¨ìœ„(ëŒ€ê°œ request ë‹¨ìœ„).
- **Span**: trace ë‚´ë¶€ì˜ ë‹¨ê³„(LLM call, retriever query, tool call, rerank, postprocess ë“±).
- **Context propagation**: ë¶„ì‚° í™˜ê²½(ì›¹ ì„œë²„ â†’ ì›Œì»¤ â†’ íˆ´ ì„œë¹„ìŠ¤)ì—ì„œë„ ë™ì¼ traceë¡œ ì—°ê²°ë˜ê²Œ í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜.

LangSmithëŠ” OpenTelemetryë¥¼ í†µí•´ â€œLLM ë‹¨ê³„ + ì¸í”„ë¼ ë‹¨ê³„â€ë¥¼ í•œ ë·°ë¡œ ë¬¶ëŠ” ë°©í–¥ì„ ê°•ì¡°í•©ë‹ˆë‹¤. íŠ¹íˆ LangChain/LangGraph ê¸°ë°˜ ì•±ì—ì„œ OTelì„ í‘œì¤€ ìˆ˜ì§‘ í¬ë§·ìœ¼ë¡œ ì“°ë„ë¡ ì§€ì›ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤. ([blog.langchain.com](https://blog.langchain.com/end-to-end-opentelemetry-langsmith?utm_source=openai))  
Langfuse ì—­ì‹œ OpenTelemetry ê¸°ë°˜ìœ¼ë¡œ spanì„ ìˆ˜ì§‘/ê°€ê³µí•˜ëŠ” ë„êµ¬ ì²´ì¸ì„ í™•ì¥í•˜ê³  ìˆê³ , ì™¸ë¶€ ì‹œìŠ¤í…œ(ì˜ˆ: Databricks MLflowë¡œ export)ê³¼ ì—°ê²°ë˜ëŠ” íë¦„ì´ ì ì  ê°•í•´ì§€ëŠ” ì¤‘ì…ë‹ˆë‹¤. ([docs.databricks.com](https://docs.databricks.com/aws/en/mlflow3/genai/tracing/third-party/langfuse?utm_source=openai))

### 2) LLM ë””ë²„ê¹…ì—ì„œ â€œê´€ì¸¡ì„±â€ì´ í•„ìš”í•œ ì´ìœ : ì¬í˜„ ê°€ëŠ¥ì„±
LLM ì¥ì• ì˜ í”í•œ ìœ í˜•ì€:
- íŠ¹ì • tool í˜¸ì¶œì´ timeout â†’ fallbackì´ ë‹¤ë¥¸ ê²½ë¡œë¡œ í˜ëŸ¬ prompt êµ¬ì„±ì´ ë‹¬ë¼ì§
- RAGì—ì„œ retrieval ê²°ê³¼ê°€ 0ê°œ â†’ hallucination ì¦ê°€
- í† í° í­ì¦ â†’ latency ê¸‰ì¦ + ë¹„ìš© ê¸‰ì¦

ì´ê±´ â€œì—ëŸ¬ ë¡œê·¸ 1ì¤„â€ë¡œ í•´ê²°ì´ ì•ˆ ë©ë‹ˆë‹¤. **ì–´ë–¤ spanì—ì„œ inputì´ ë¬´ì—‡ì´ì—ˆê³ , output tokenì´ ì–¼ë§ˆë‚˜ ë‚˜ì™”ê³ , ì¬ì‹œë„ê°€ ëª‡ ë²ˆ ë°œìƒí–ˆëŠ”ì§€**ê°€ ë³´ì´ëŠ” traceê°€ í•„ìš”í•©ë‹ˆë‹¤.

### 3) ë¹„ìš© ì¶”ì (Cost tracking)ì˜ ë‘ ì¸µ: â€œìë™â€ vs â€œìˆ˜ë™â€
LangSmithëŠ” ë¹„ìš©ì„ (a) token count + ëª¨ë¸ ê°€ê²©í‘œë¡œ **ìë™ íŒŒìƒ**í•˜ê±°ë‚˜, (b) runì— costë¥¼ **ìˆ˜ë™ìœ¼ë¡œ ì£¼ì…**í•˜ëŠ” ë‘ ê²½ë¡œë¥¼ ëª…ì‹œí•©ë‹ˆë‹¤. ([docs.langchain.com](https://docs.langchain.com/langsmith/cost-tracking?utm_source=openai))  
ì‹¤ë¬´ì ìœ¼ë¡œëŠ”:
- OpenAI/Anthropic ë“± í‘œì¤€ ê³¼ê¸ˆ ëª¨ë¸ì€ ìë™ì´ í¸í•¨
- ìì²´ í˜¸ìŠ¤íŒ… ëª¨ë¸/ë²ˆë“¤ ê³¼ê¸ˆ/íˆ´ í˜¸ì¶œ ë¹„ìš©ê¹Œì§€ í•©ì‚°í•˜ë ¤ë©´ ìˆ˜ë™ ì£¼ì…ì´ í•„ìˆ˜

### 4) 2026ë…„ ì„ íƒ ê¸°ì¤€ì˜ ë³¸ì§ˆ: â€œOTel íŒŒì´í”„ë¼ì¸ì„ ëˆ„ê°€ ì£¼ë„í•˜ë‚˜â€
- LangSmith ìª½ì€ â€œLangChain/LangGraph ì•±ì„ ë¹ ë¥´ê²Œ ìš´ì˜â€ + LangSmith UI/í‰ê°€/ëª¨ë‹ˆí„°ë§ì— ìµœì í™”(OTelë„ ì§€ì›). ([blog.langchain.com](https://blog.langchain.com/end-to-end-opentelemetry-langsmith?utm_source=openai))
- Langfuse ìª½ì€ â€œOpenTelemetry ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬/SDKì—ì„œ spanì„ ëª¨ì•„â€ Langfuse(ë˜ëŠ” ë‹¤ë¥¸ OTLP backend)ë¡œ ë³´ë‚´ëŠ” ì˜µì…˜ì´ ê°•í•´ì§€ëŠ” ì¤‘. íŠ¹íˆ Node.js 20+ ì¤‘ì‹¬ìœ¼ë¡œ OTEL export ìœ í‹¸(@langfuse/otel)ì´ ëª…í™•í•©ë‹ˆë‹¤. ([npmjs.com](https://www.npmjs.com/package/%40langfuse/otel?utm_source=openai))

---

## ğŸ’» ì‹¤ì „ ì½”ë“œ
ì•„ë˜ ì˜ˆì œëŠ” â€œí•œ ë²ˆì˜ ì‚¬ìš©ì ìš”ì²­â€ì„ traceë¡œ ë¬¶ê³ , ë‚´ë¶€ì—ì„œ LLM í˜¸ì¶œ/ì¶”ê°€ ì‘ì—…(span)ì„ ë‚¨ê¸°ë©°, **ë¹„ìš©/í† í° í­ì¦ê³¼ ê°™ì€ ìš´ì˜ ì´ìŠˆë¥¼ ë‚˜ì¤‘ì— ì—­ì¶”ì **í•  ìˆ˜ ìˆê²Œ ë§Œë“œëŠ” ìµœì†Œ ë‹¨ìœ„ì…ë‹ˆë‹¤.

### (A) LangSmith: OpenTelemetry í™œì„±í™” + LangChain í˜¸ì¶œ (Python)
LangSmithëŠ” `langsmith[otel]` ì„¤ì¹˜ ë° í™˜ê²½ë³€ìˆ˜ë¡œ OTel ê¸°ë°˜ tracingì„ ì¼¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ([blog.langchain.com](https://blog.langchain.com/end-to-end-opentelemetry-langsmith?utm_source=openai))

```python
# python
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# 1) í™˜ê²½ ë³€ìˆ˜ë¡œ LangSmith + OTel tracing í™œì„±í™”
# (ìš´ì˜ì—ì„œëŠ” Secret Managerë¡œ ì£¼ì… ê¶Œì¥)
os.environ["LANGSMITH_OTEL_ENABLED"] = "true"
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGSMITH_API_KEY"] = os.getenv("LANGSMITH_API_KEY", "<YOUR_LANGSMITH_API_KEY>")
os.environ["LANGSMITH_PROJECT"] = "prod-llm-observability"

# 2) ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ: ì²´ì¸ ì‹¤í–‰ì´ traceë¡œ ìë™ ìˆ˜ì§‘ë˜ë„ë¡ êµ¬ì„±
prompt = ChatPromptTemplate.from_template(
    "You are a strict assistant. Answer briefly.\nQuestion: {q}"
)
model = ChatOpenAI(model="gpt-4o-mini")  # ì˜ˆì‹œ

chain = prompt | model

def handle_request(user_question: str) -> str:
    # ì´ í•¨ìˆ˜ 1íšŒ í˜¸ì¶œì´ ë³´í†µ 'ìš”ì²­ 1ê±´' = trace 1ê°œë¡œ ì—°ê²°ë¨(êµ¬ì„±ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    result = chain.invoke({"q": user_question})
    return result.content

if __name__ == "__main__":
    print(handle_request("Explain why RAG can increase latency."))
```

í¬ì¸íŠ¸:
- â€œLLM callì´ ì–´ë””ì„œ ì–¼ë§ˆë‚˜ ëŠë¦°ì§€â€, â€œì–´ë–¤ promptê°€ ë¹„ìš©ì„ í­ì¦ì‹œí‚¤ëŠ”ì§€â€ëŠ” **spanì˜ attributes/token/cost**ê°€ ìŒ“ì—¬ì•¼ ë³´ì…ë‹ˆë‹¤.
- LangSmithëŠ” ë¹„ìš© ì¶”ì ì„ ìë™ íŒŒìƒ/ìˆ˜ë™ ì£¼ì… ëª¨ë‘ ì§€ì›í•œë‹¤ëŠ” ì ì„ ë¬¸ì„œë¡œ ëª…í™•íˆ í•©ë‹ˆë‹¤. ([docs.langchain.com](https://docs.langchain.com/langsmith/cost-tracking?utm_source=openai))

### (B) Langfuse: OpenTelemetry Span Processorë¥¼ ë¶™ì—¬ Nodeì—ì„œ export (TypeScript)
LangfuseëŠ” JS SDKë¥¼ OpenTelemetry ê¸°ë°˜ìœ¼ë¡œ ì¬êµ¬ì„±í–ˆê³ , `LangfuseSpanProcessor`ë¥¼ ì œê³µí•˜ëŠ” `@langfuse/otel` íŒ¨í‚¤ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤(ë§ˆìŠ¤í‚¹/í•„í„°ë§/ë¯¸ë””ì–´ ì²˜ë¦¬ í¬í•¨). ([npmjs.com](https://www.npmjs.com/package/%40langfuse/otel?utm_source=openai))

```ts
// typescript
// Node.js 20+ ê¶Œì¥(íŒ¨í‚¤ì§€ ì„¤ëª… ê¸°ì¤€). ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„  dotenv/secret manager ì‚¬ìš©.
import { NodeSDK } from "@opentelemetry/sdk-node";
import { getNodeAutoInstrumentations } from "@opentelemetry/auto-instrumentations-node";
import { LangfuseSpanProcessor } from "@langfuse/otel";
import { trace } from "@opentelemetry/api";

// 1) Langfuse ì¸ì¦/í˜¸ìŠ¤íŠ¸ ì„¤ì • (Cloud ë˜ëŠ” self-hosted)
process.env.LANGFUSE_HOST = process.env.LANGFUSE_HOST ?? "https://cloud.langfuse.com";
process.env.LANGFUSE_PUBLIC_KEY = process.env.LANGFUSE_PUBLIC_KEY ?? "<PUBLIC_KEY>";
process.env.LANGFUSE_SECRET_KEY = process.env.LANGFUSE_SECRET_KEY ?? "<SECRET_KEY>";

const sdk = new NodeSDK({
  instrumentations: [getNodeAutoInstrumentations()],
  // í•µì‹¬: LangfuseSpanProcessorë¡œ OTEL spanì„ Langfuseë¡œ export
  spanProcessors: [
    new LangfuseSpanProcessor({
      // ìš´ì˜ íŒ: ë§ˆìŠ¤í‚¹/í•„í„°ë§ ì •ì±…ì„ ì—¬ê¸°ì„œ ê°•ì œí•´ PII ìœ ì¶œì„ ë§‰ëŠ” ì‹ìœ¼ë¡œ ì‚¬ìš©
      // (êµ¬ì²´ ì˜µì…˜ì€ Langfuse ë¬¸ì„œ/ë ˆí¼ëŸ°ìŠ¤ì— ë”°ë¦„)
    }),
  ],
});

async function main() {
  await sdk.start();

  // 2) ìˆ˜ë™ span ì˜ˆì‹œ: "ìš”ì²­ 1ê±´"ì„ ìµœìƒìœ„ spanìœ¼ë¡œ ê°ì‹¸ê³  ë‚´ë¶€ ì‘ì—…ì„ ìì‹ spanìœ¼ë¡œ êµ¬ì„±
  const tracer = trace.getTracer("llm-app");

  await tracer.startActiveSpan("chat.request", async (rootSpan) => {
    try {
      rootSpan.setAttribute("env", "production");
      rootSpan.setAttribute("feature", "support-chat");

      await tracer.startActiveSpan("llm.call", async (span) => {
        // ì—¬ê¸°ì—ì„œ OpenAI SDK/LangChain í˜¸ì¶œ ë“±ì„ ìˆ˜í–‰
        // token/costëŠ” SDK í†µí•© ë˜ëŠ” attributeë¡œ ê¸°ë¡(ë„êµ¬/í†µí•© ë°©ì‹ì— ë”°ë¼ ë‹¤ë¦„)
        span.setAttribute("model", "gpt-4o-mini");
        await new Promise((r) => setTimeout(r, 150)); // ì˜ˆì‹œ ì§€ì—°
        span.end();
      });

      rootSpan.end();
    } catch (e) {
      rootSpan.recordException(e as Error);
      rootSpan.setStatus({ code: 2 }); // ERROR
      rootSpan.end();
      throw e;
    }
  });

  await sdk.shutdown();
}

main().catch((e) => {
  console.error(e);
  process.exit(1);
});
```

í¬ì¸íŠ¸:
- Langfuseì˜ ë°©í–¥ì„±ì€ â€œOTelë¡œ ë“¤ì–´ì˜¤ëŠ” spanì„ Langfuseì—ì„œ í•´ì„/ì‹œê°í™”â€í•˜ëŠ” í‘œì¤€ íŒŒì´í”„ë¼ì¸ì— ê°€ê¹ìŠµë‹ˆë‹¤.
- Databricks ë¬¸ì„œëŠ” Langfuse traceë¥¼ OTEL ê¸°ë°˜ìœ¼ë¡œ ì™¸ë¶€ë¡œ exportí•˜ëŠ” ì˜ˆë¥¼ ê³µì‹ ê°€ì´ë“œë¡œ ì œê³µí•˜ê³  ìˆì–´, â€œLangfuseì—ë§Œ ë¬¶ì´ì§€ ì•ŠëŠ” ìš´ì˜â€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ([docs.databricks.com](https://docs.databricks.com/aws/en/mlflow3/genai/tracing/third-party/langfuse?utm_source=openai))

---

## âš¡ ì‹¤ì „ íŒ
1) **Trace ë¹„ìš© í­íƒ„ì˜ 1ì°¨ ì›ì¸ì€ â€˜ìƒ˜í”Œë§ ë¶€ì¬â€™**
- ëª¨ë“  ìš”ì²­ì„ 100% traceí•˜ë©´ ë””ë²„ê¹…ì—” ì¢‹ì§€ë§Œ, ë¹„ìš©/ì €ì¥/PII ë¦¬ìŠ¤í¬ê°€ í­ë°œí•©ë‹ˆë‹¤.
- ê¶Œì¥: `error` ë˜ëŠ” `slow request`ëŠ” 100%, ì •ìƒ íŠ¸ë˜í”½ì€ í™•ë¥  ìƒ˜í”Œë§(ì˜ˆ: 1~5%) + íŠ¹ì • ê³ ê°/ê¸°ëŠ¥ì€ ê³ ì • ìƒ˜í”Œë§.

2) **â€œìš”ì²­ 1ê±´ = trace 1ê°œâ€ë¡œ ê³¼ê¸ˆ/ì§€í‘œë¥¼ ë§ì¶”ëŠ” ìŠµê´€**
LangSmithëŠ” í”Œëœì—ì„œ trace ë‹¨ìœ„ ê³¼ê¸ˆ/í¬í•¨ëŸ‰ì„ ëª…í™•íˆ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤(ë¬´ë£Œ/Plus í¬í•¨ trace, ì´ˆê³¼ ê³¼ê¸ˆ ë“±). ([langchain.com](https://www.langchain.com/pricing?utm_source=openai))  
ì‹¤ë¬´ì—ì„  trace ì •ì˜ê°€ í”ë“¤ë¦¬ë©´ KPIë„ í”ë“¤ë¦½ë‹ˆë‹¤.
- API Gateway / Backend entryì—ì„œ root spanì„ ë§Œë“¤ê³ 
- ë‚´ë¶€ chain/agent ë‹¨ê³„ëŠ” child spanìœ¼ë¡œë§Œ ìª¼ê°œê¸°

3) **ë¹„ìš© ì¶”ì ì€ â€œLLMë§Œâ€ì´ ì•„ë‹ˆë¼ â€œíˆ´ í˜¸ì¶œê¹Œì§€â€ í•©ì‚°í•´ì•¼ ì˜ë¯¸ê°€ ìƒê¹€**
LangSmith ë¬¸ì„œë„ ìˆ˜ë™ ë¹„ìš© ì£¼ì…ì„ ëª…ì‹œí•œ ì´ìœ ê°€ ì—¬ê¸° ìˆìŠµë‹ˆë‹¤. ([docs.langchain.com](https://docs.langchain.com/langsmith/cost-tracking?utm_source=openai))  
ì˜ˆ: ì›¹ ê²€ìƒ‰(tool) í˜¸ì¶œ, reranker, OCR, DB ì¿¼ë¦¬, GPU inference ë“± â€œLLM ì™¸ ë¹„ìš©â€ì´ ë” í° ì„œë¹„ìŠ¤ê°€ í”í•©ë‹ˆë‹¤.

4) **OTelì„ ì±„íƒí•˜ë©´ â€˜ë²¤ë” ë½ì¸â€™ì´ ì•„ë‹ˆë¼ â€˜ë²¤ë” ìŠ¤ìœ„ì¹­ ë¹„ìš©â€™ì´ ì¤„ì–´ë“¦**
LangSmithê°€ end-to-end OTelì„ ê°•ì¡°í•˜ëŠ” ê²ƒë„ â€œí‘œì¤€ ê³„ì¸µâ€ì„ í™•ë³´í•´ observabilityë¥¼ ìŠ¤íƒ ì „ì²´ë¡œ í™•ì¥í•˜ë ¤ëŠ” íë¦„ì…ë‹ˆë‹¤. ([blog.langchain.com](https://blog.langchain.com/end-to-end-opentelemetry-langsmith?utm_source=openai))  
LangfuseëŠ” OTel ê¸°ë°˜ SDK/processorë¡œ ê·¸ íë¦„ì„ ë” ê°•í•˜ê²Œ íƒ‘ë‹ˆë‹¤. ([npmjs.com](https://www.npmjs.com/package/%40langfuse/otel?utm_source=openai))  
ê²°ë¡ : ì§€ê¸ˆ ìƒˆë¡œ ì„¤ê³„í•œë‹¤ë©´ â€œë„êµ¬ë¥¼ ë¬´ì—‡ì„ ì“°ë“ â€ **OTel ì»¨í…ìŠ¤íŠ¸/attribute ê·œì¹™ì„ íŒ€ í‘œì¤€ìœ¼ë¡œ ë¨¼ì € ì •í•˜ëŠ” ê²Œ** ì¥ê¸°ì ìœ¼ë¡œ ì´ê¹ë‹ˆë‹¤.

5) **PII/í”„ë¡¬í”„íŠ¸ ìœ ì¶œ ë°©ì§€ëŠ” â€˜ë§ˆìŠ¤í‚¹â€™ì´ ì•„ë‹ˆë¼ â€˜ê¸°ë³¸ ë¹„ìˆ˜ì§‘â€™ìœ¼ë¡œ**
- â€œí•„ìš”í•  ë•Œë§Œ verboseâ€ê°€ ì•ˆì „í•©ë‹ˆë‹¤.
- Langfuse exporter ê³„ì—´ ë¬¸ì„œì—ì„œë„ ë³´ì•ˆìƒ ì¼ë¶€ ë‚´ìš©ì„ ê¸°ë³¸ ë§ˆìŠ¤í‚¹í•˜ê³  verbose ì˜µì…˜ìœ¼ë¡œ ë…¸ì¶œí•˜ëŠ” íŒ¨í„´ì´ ë³´ì…ë‹ˆë‹¤. ([docs.koog.ai](https://docs.koog.ai/opentelemetry-langfuse-exporter/?utm_source=openai))

---

## ğŸš€ ë§ˆë¬´ë¦¬
LangSmithì™€ Langfuseë¥¼ 2026ë…„ 3ì›” ì‹œì ì—ì„œ ë³´ë©´, ê²½ìŸ í¬ì¸íŠ¸ëŠ” UIë‚˜ ê¸°ëŠ¥ ëª‡ ê°œê°€ ì•„ë‹ˆë¼ **í‘œì¤€(OpenTelemetry) ìœ„ì—ì„œ ë””ë²„ê¹…/ë¹„ìš©/í‰ê°€ë¥¼ ì–¼ë§ˆë‚˜ ìš´ì˜ ì¹œí™”ì ìœ¼ë¡œ ë¬¶ì–´ì£¼ëŠëƒ**ì…ë‹ˆë‹¤.  
- LangSmith: LangChain/LangGraph ì¤‘ì‹¬ íŒ€ì´ â€œë¹ ë¥´ê²Œ tracing+cost dashboardâ€ê¹Œì§€ ê°€ëŠ” ë° ê°•ì (OTel end-to-end ì§€ì›, ë¹„ìš© ì¶”ì  ê°€ì´ë“œ/ëŒ€ì‹œë³´ë“œ). ([blog.langchain.com](https://blog.langchain.com/end-to-end-opentelemetry-langsmith?utm_source=openai))  
- Langfuse: ì˜¤í”ˆì†ŒìŠ¤/ìì²´ í˜¸ìŠ¤íŒ…/OTel íŒŒì´í”„ë¼ì¸ ì¤‘ì‹¬ìœ¼ë¡œ â€œìˆ˜ì§‘â†’ê°€ê³µâ†’ì™¸ë¶€ exportâ€ê¹Œì§€ ìœ ì—°ì„±ì„ í™•ë³´í•˜ëŠ” ë°©í–¥(OTEL JS SDK v4, @langfuse/otel). ([github.com](https://github.com/orgs/langfuse/discussions/8403?utm_source=openai))

ë‹¤ìŒ í•™ìŠµ ì¶”ì²œì€ 2ê°€ì§€ì…ë‹ˆë‹¤.
1) íŒ€ í‘œì¤€ìœ¼ë¡œ **trace attribute ê·œì•½(model, feature, customer_tier, session_id, prompt_version, retriever_topk, cache_hit ë“±)**ì„ ì •í•˜ê³ ,  
2) OTel Collectorë¥¼ ì¤‘ê°„ì— ë‘ëŠ” êµ¬ì¡°(ìƒ˜í”Œë§/ë¦¬ë‹¤ì´ë ‰íŠ¸/ë§ˆìŠ¤í‚¹ ì¤‘ì•™ì§‘ì¤‘)ë¥¼ ì„¤ê³„í•´ â€œë„êµ¬ êµì²´ ê°€ëŠ¥í•œ ê´€ì¸¡ì„±â€ì„ ì™„ì„±í•˜ì„¸ìš”. LangSmithë„ OTel ê¸°ë°˜ ë¶„ì‚° tracing íë¦„ì„ ì ê·¹ì ìœ¼ë¡œ ì•ˆë‚´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ([blog.langchain.com](https://blog.langchain.com/opentelemetry-langsmith?utm_source=openai))
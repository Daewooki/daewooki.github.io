---
title: "ì‹¤ì‹œê°„ ìŒì„± ì—ì´ì „íŠ¸ 2026ë…„ 2ì›”íŒ: STT/TTSë¥¼ â€œíŒŒì´í”„ë¼ì¸â€ì´ ì•„ë‹Œ â€œìŠ¤íŠ¸ë¦¬ë° ëŸ°íƒ€ì„â€ìœ¼ë¡œ ë‹¤ë£¨ëŠ” ë²•"
date: 2026-02-05 02:45:06 +0900
categories: [AI, Multimodal]
tags: [ai, multimodal, trend, 2026-02]
---

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7990TVG7C7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7990TVG7C7');
</script>

## ë“¤ì–´ê°€ë©°
2026ë…„ 2ì›” ê¸°ì¤€, â€œìŒì„± AIâ€ì˜ ìŠ¹ë¶€ì²˜ëŠ” ëª¨ë¸ ì„±ëŠ¥ ìì²´ë³´ë‹¤ **ëŒ€í™”ì˜ ë¦¬ë“¬(í„´ ì „í™˜, ë¼ì–´ë“¤ê¸°, ì§€ì—°, ëŠê¹€ ë³µêµ¬)** ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì±—ë´‡ì€ 1~2ì´ˆ ì§€ì—°ë„ ìš©ë‚©ë˜ì§€ë§Œ, ìŒì„± ëŒ€í™”ëŠ” **ì²« ì†Œë¦¬(First audio)ê¹Œì§€ 600~900ms**, í„´ ì „ì²´ê°€ 1~2ì´ˆëŒ€ë¥¼ ë„˜ê¸°ë©´ ì‚¬ìš©ìê°€ ì¦‰ì‹œ â€œê¸°ê³„ë‘ ë§í•œë‹¤â€ëŠ” ëŠë‚Œì„ ë°›ìŠµë‹ˆë‹¤. (í˜„ì—…ì—ì„œ í”íˆ ë³´ëŠ” 3ì´ˆ+ ì§€ì—°ì€ ëŒ€ê°œ â€œë²„í¼ë§/í„´ ê°ì§€â€ ì„¤ê³„ ë¬¸ì œë¡œ ê·€ê²°ë©ë‹ˆë‹¤.)

ìµœê·¼ íŠ¸ë Œë“œëŠ” ëª…í™•í•©ë‹ˆë‹¤.

- **Speech-to-Speech(=STS) / Realtime ëª¨ë¸ + ìŠ¤íŠ¸ë¦¬ë° í”„ë¡œí† ì½œ(WebRTC/WebSocket)** ë¡œ â€œí…ìŠ¤íŠ¸ ì¤‘ê°„ ë‹¨ê³„ë¥¼ ìµœì†Œí™”â€ (OpenAI Realtime/Voice Agents, Azure Realtime) ([openai.github.io](https://openai.github.io/openai-agents-js/guides/voice-agents/))  
- **VAD(Voice Activity Detection) ê¸°ë°˜ì˜ barge-in(ë¼ì–´ë“¤ê¸°) + ì„œë²„ê°€ ì¦‰ì‹œ generation cancel** (Gemini Live API) ([ai.google.dev](https://ai.google.dev/gemini-api/docs/live-guide))  
- **STT/TTS/LLM orchestrationì„ í•œ APIë¡œ ë¬¶ì–´ ì§€ì—°ê³¼ ë³µì¡ë„ë¥¼ ì¤„ì´ëŠ” í†µí•©í˜• Voice Agent API** (Deepgram Voice Agent API GA) ([deepgram.com](https://deepgram.com/learn/voice-agent-api-generally-available))  
- ì—”í„°í”„ë¼ì´ì¦ˆëŠ” â€œë‚´ë¶€ë§/í´ë¼ìš°ë“œ ê²½ê³„â€ ë•Œë¬¸ì— **SageMaker ì‹¤ì‹œê°„ ì—”ë“œí¬ì¸íŠ¸ ê°™ì€ ë°°í¬ ê²½ë¡œ**ë¥¼ ì„ í˜¸ (Deepgram on SageMaker) ([press.aboutamazon.com](https://press.aboutamazon.com/aws/2025/11/deepgram-launches-streaming-speech-text-and-voice-agents-on-amazon-sagemaker-ai?utm_source=openai))  

ì´ ê¸€ì€ â€œì‹¤ì‹œê°„ ìŒì„± ëŒ€í™” êµ¬í˜„â€ì„ ëª©í‘œë¡œ, **í„´ ì„¤ê³„/ìŠ¤íŠ¸ë¦¬ë°/ì¸í„°ëŸ½íŠ¸**ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì¡°ë¥¼ ì¡ì•„ë´…ë‹ˆë‹¤.

---

## ğŸ”§ í•µì‹¬ ê°œë…
### 1) íŒŒì´í”„ë¼ì¸(ASRâ†’LLMâ†’TTS) vs Realtime/STS ëŸ°íƒ€ì„
ì „í†µ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1) STTê°€ ë¬¸ì¥ì„ â€œí™•ì •(final)â€  
2) LLMì´ í…ìŠ¤íŠ¸ ì‘ë‹µ ìƒì„±  
3) TTSê°€ ìŒì„± í•©ì„±  

ë¬¸ì œëŠ” **(1)ì—ì„œ finalì„ ê¸°ë‹¤ë¦¬ëŠ” ìˆœê°„ ëŒ€í™”ê°€ ì£½ëŠ”ë‹¤**ëŠ” ì ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ 2025~2026ì˜ ì‹¤ì‹œê°„ APIë“¤ì€ ë‹¤ìŒì„ ê¸°ë³¸ìœ¼ë¡œ ê¹ë‹ˆë‹¤.

- **Streaming input**: 20ms~60ms ë‹¨ìœ„ ì˜¤ë””ì˜¤ í”„ë ˆì„ì„ ì§€ì† ì „ì†¡  
- **Partial ê²°ê³¼**: partial transcript/partial audioë¥¼ ì¦‰ì‹œ ë°›ìŒ  
- **Interrupt**: ì‚¬ìš©ìê°€ ë§í•˜ë©´ ì„œë²„ê°€ í˜„ì¬ ìƒì„± ì¤‘ ì‘ë‹µì„ â€œì·¨ì†Œ(cancellation)â€  

Gemini Live API ë¬¸ì„œì—ì„  VADë¡œ ë¼ì–´ë“¤ê¸°ë¥¼ ê°ì§€í•˜ë©´ **ì§„í–‰ ì¤‘ generationì„ cancel/discard**í•˜ê³ , ì·¨ì†Œëœ tool callê¹Œì§€ ì •ë¦¬í•œë‹¤ê³  ëª…ì‹œí•©ë‹ˆë‹¤. ([ai.google.dev](https://ai.google.dev/gemini-api/docs/live-guide))  

Azure OpenAI(=GPT Realtime) ìª½ì€ íŠ¹íˆ **WebRTCê°€ ì €ì§€ì—°ì— ìœ ë¦¬**í•˜ë©° WebSocketì€ â€œì„œë²„-ì„œë²„ ì‹œë‚˜ë¦¬ì˜¤â€ì— ë” ê°€ê¹ë‹¤ê³  ê°€ì´ë“œí•©ë‹ˆë‹¤. ì¦‰, ë¸Œë¼ìš°ì €/ëª¨ë°”ì¼ ì‹¤ì‹œê°„ ìŒì„±ì€ WebRTCë¥¼ ìš°ì„  ê³ ë ¤í•˜ëŠ” ê²Œ ë§ìŠµë‹ˆë‹¤. ([learn.microsoft.com](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/realtime-audio-webrtc))  

OpenAI Agents SDKì˜ Voice Agentsë„ WebSocket/WebRTC ì—°ê²°ê³¼ interruption handlingì„ â€œSDK ë ˆë²¨ ê¸°ëŠ¥â€ìœ¼ë¡œ ì˜¬ë ¤ë‘” ê²Œ í¬ì¸íŠ¸ì…ë‹ˆë‹¤. ([openai.github.io](https://openai.github.io/openai-agents-js/guides/voice-agents/))  

### 2) ì§€ì—°ì„ ìª¼ê°œì„œ ê´€ë¦¬í•˜ë¼ (Latency Budget)
ì‹¤ì‹œê°„ ìŒì„± ì—ì´ì „íŠ¸ì˜ ì§€ì—°ì€ ëŒ€ê°œ ë‹¤ìŒ í•©ì…ë‹ˆë‹¤.

- **Capture/Encode**: ë§ˆì´í¬ ìº¡ì²˜ + Opus/PCM ì¸ì½”ë”©
- **Network jitter**: ì—…ë§í¬ ì§€í„°/ì†ì‹¤
- **VAD ê²°ì • ì§€ì—°**: â€œì‚¬ìš©ì ë°œí™”ê°€ ëë‚¬ë‹¤â€ë¥¼ íŒë‹¨í•˜ëŠ” hangover
- **Model thinking**: ì²« í† í°/ì²« ì˜¤ë””ì˜¤ ì²­í¬
- **Playback buffer**: ì¬ìƒì¸¡ ë²„í¼(ë„ˆë¬´ ë‘ê»ê²Œ ì¡ìœ¼ë©´ ì²´ê° ì§€ì—° ê¸‰ì¦)

ì—¬ê¸°ì„œ ê°€ì¥ í”í•œ í•¨ì •ì€:
- VADë¥¼ ë„ˆë¬´ ë³´ìˆ˜ì ìœ¼ë¡œ ì¡ì•„ **í„´ ì¢…ë£Œë¥¼ ëŠ¦ê²Œ í™•ì •**
- ì„œë²„ê°€ â€œì‚¬ìš©ì ì˜¤ë””ì˜¤ë¥¼ ì¼ì • ê¸¸ì´ë¡œ ëª¨ì•„ì„œâ€ ë³´ë‚´ **ê°€ì§œ ìŠ¤íŠ¸ë¦¬ë°**
- ì¬ìƒ ë²„í¼ë¥¼ ì•ˆì „í•˜ê²Œ ì¡ë‹¤ê°€ **ëŒ€í™” ë¦¬ë“¬ íŒŒê´´**

### 3) â€œì—ì´ì „íŠ¸â€ëŠ” ìŒì„±ë§Œì´ ì•„ë‹ˆë¼ Tool/State ë¨¸ì‹ ì´ë‹¤
ìš”ì¦˜ Voice Agent APIë“¤ì´ â€œSTT/TTS + orchestrationâ€ì„ ê°•ì¡°í•˜ëŠ” ì´ìœ ëŠ” ë‹¨ìˆœí•©ë‹ˆë‹¤.  
ì‹¤ì „ ìŒì„±ë´‡ì€ ê²°êµ­:

- ìƒíƒœ(state): ì¸ì¦/ì£¼ë¬¸/ì˜ˆì•½/CS í‹°ì¼“ ë“±
- íˆ´(tool): DB ì¡°íšŒ, CRM ì—…ë°ì´íŠ¸, ê²€ìƒ‰, ê²°ì œ, ì½œ ë¼ìš°íŒ…
- ê°€ë“œë ˆì¼(guardrails): ê¸ˆì¹™ì–´/ê°œì¸ì •ë³´/ì •ì±…

Deepgramì€ Voice Agent APIë¥¼ **ë‹¨ì¼ ìŠ¤íŠ¸ë¦¬ë° APIë¡œ í†µí•©**í•´ latency/ë³µì¡ë„ë¥¼ ì¤„ì˜€ë‹¤ê³  ê°•ì¡°í•©ë‹ˆë‹¤. ([deepgram.com](https://deepgram.com/learn/voice-agent-api-generally-available))  

---

## ğŸ’» ì‹¤ì „ ì½”ë“œ
ì•„ë˜ ì˜ˆì‹œëŠ” **â€œWebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„± ì„¸ì…˜â€ì˜ ìµœì†Œ ê³¨ê²©**ì…ë‹ˆë‹¤. (ë¸Œë¼ìš°ì € ì‹¤ì‹œê°„ì€ WebRTC ê¶Œì¥ì´ë¼ëŠ” ì ì€ ìœ ì§€í•˜ë˜, ì„œë²„ì—ì„œ ë¹ ë¥´ê²Œ ê²€ì¦í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ì‘ì„±) Azure OpenAI Realtime WebSocket êµ¬ì¡°(ì„¸ì…˜/ì´ë²¤íŠ¸ ê¸°ë°˜)ì™€ ë™ì¼í•œ â€œì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼â€ íŒ¨í„´ìœ¼ë¡œ ì„¤ê³„í•©ë‹ˆë‹¤. ([learn.microsoft.com](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/realtime-audio-websockets?utm_source=openai))  

ì˜ˆì œ ëª©í‘œ:
- ë§ˆì´í¬ ì…ë ¥(PCM 16k) â†’ ì„œë²„ â†’ Realtime API
- ì‘ë‹µ ì˜¤ë””ì˜¤ chunk ìˆ˜ì‹  â†’ ì¦‰ì‹œ ì¬ìƒ íì— ì ì¬
- ì‚¬ìš©ì ë°œí™” ê°ì§€ ì‹œ **cancel(ì¸í„°ëŸ½íŠ¸)** ë¥¼ ë„£ì„ ìˆ˜ ìˆëŠ” êµ¬ì¡°

```python
# python 3.11+
# pip install websockets sounddevice numpy

import asyncio, base64, json
import numpy as np
import sounddevice as sd
import websockets

SAMPLE_RATE = 16000
FRAME_MS = 20
FRAME_SAMPLES = SAMPLE_RATE * FRAME_MS // 1000

# Azure OpenAI Realtime(WebSocket) ì—°ê²° ì˜ˆì‹œ í˜•ì‹:
# wss://{resource}.openai.azure.com/openai/v1/realtime?model={deployment}
# (í™˜ê²½ì— ë”°ë¼ api-version íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ)  ([learn.microsoft.com](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/realtime-audio-websockets?utm_source=openai))
AZURE_WSS_URL = "wss://YOUR_RESOURCE.openai.azure.com/openai/v1/realtime?model=YOUR_DEPLOYMENT"
AZURE_API_KEY = "YOUR_API_KEY"

def pcm16_to_b64(pcm16: np.ndarray) -> str:
    # pcm16: int16 mono
    return base64.b64encode(pcm16.tobytes()).decode("ascii")

async def mic_stream(q: asyncio.Queue):
    # ë§ˆì´í¬ ìº¡ì²˜ëŠ” ë³„ë„ ìŠ¤ë ˆë“œ ì½œë°±ìœ¼ë¡œ ë“¤ì–´ì˜¤ë¯€ë¡œ asyncio queueë¡œ ë¸Œë¦¿ì§€
    loop = asyncio.get_running_loop()

    def callback(indata, frames, time, status):
        if status:
            # ì‹¤ì œ ì„œë¹„ìŠ¤ë¼ë©´ ë¡œê¹…/ë©”íŠ¸ë¦­
            pass
        pcm16 = (indata[:, 0] * 32767.0).astype(np.int16)
        loop.call_soon_threadsafe(q.put_nowait, pcm16)

    with sd.InputStream(
        channels=1,
        samplerate=SAMPLE_RATE,
        blocksize=FRAME_SAMPLES,
        dtype="float32",
        callback=callback,
    ):
        while True:
            await asyncio.sleep(1)

async def run():
    mic_q = asyncio.Queue()

    # 1) ë§ˆì´í¬ íƒœìŠ¤í¬ ì‹œì‘
    asyncio.create_task(mic_stream(mic_q))

    headers = {
        # WebSocket í•¸ë“œì…°ì´í¬ í—¤ë”ë¡œ api-key ì „ë‹¬(ë¸Œë¼ìš°ì €ëŠ” ë¶ˆê°€í•œ ê²½ìš°ê°€ ë§ìŒ) ([learn.microsoft.com](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/realtime-audio-websockets?utm_source=openai))
        "api-key": AZURE_API_KEY,
    }

    async with websockets.connect(AZURE_WSS_URL, extra_headers=headers) as ws:
        # 2) (ì„ íƒ) ì„¸ì…˜ ì„¤ì • ì´ë²¤íŠ¸ ì „ì†¡
        # ì‹¤ì œ ì´ë²¤íŠ¸ ëª…/ìŠ¤í‚¤ë§ˆëŠ” ì œê³µìë³„ë¡œ ë‹¤ë¥´ì§€ë§Œ,
        # í•µì‹¬ì€ "ì…ë ¥ ì˜¤ë””ì˜¤ í¬ë§·/ì¶œë ¥ ëª¨ë‹¬ë¦¬í‹°(audio)"ë¥¼ ëª…ì‹œí•˜ëŠ” ê²ƒ.
        await ws.send(json.dumps({
            "type": "session.update",
            "session": {
                "input_audio_format": {"type": "pcm16", "sample_rate_hz": SAMPLE_RATE},
                "output_audio_format": {"type": "pcm16", "sample_rate_hz": SAMPLE_RATE},
                "response_modalities": ["audio"],
            }
        }))

        async def sender():
            while True:
                pcm16 = await mic_q.get()
                await ws.send(json.dumps({
                    "type": "input_audio_buffer.append",
                    "audio": pcm16_to_b64(pcm16),
                }))

        async def receiver():
            while True:
                msg = json.loads(await ws.recv())

                # 3) ì„œë²„ê°€ ë³´ë‚´ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ë¥¼ ë°›ì•„ ì²˜ë¦¬
                t = msg.get("type")

                if t == "response.audio.delta":
                    # ì‘ë‹µ ì˜¤ë””ì˜¤ ì¡°ê°(PCM16 base64)ì„ ë°”ë¡œ ì¬ìƒ íë¡œ ë„£ëŠ” êµ¬ì¡°ë¥¼ ê¶Œì¥
                    audio_b64 = msg["delta"]
                    pcm = np.frombuffer(base64.b64decode(audio_b64), dtype=np.int16)
                    sd.play(pcm.astype(np.float32) / 32767.0, SAMPLE_RATE, blocking=False)

                elif t == "response.completed":
                    # í•œ í„´ ì™„ë£Œ
                    pass

                elif t == "input_audio_buffer.speech_started":
                    # ì‚¬ìš©ì ë°œí™” ì‹œì‘ì„ ê°ì§€í–ˆë‹¤ë©´, ì§€ê¸ˆ ì¬ìƒ ì¤‘ì¸ TTSë¥¼ ë©ˆì¶”ê³ 
                    # ìƒì„± ì¤‘ ì‘ë‹µì„ ì·¨ì†Œí•˜ëŠ” "barge-in"ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŒ
                    # (Gemini LiveëŠ” VAD ì¸í„°ëŸ½íŠ¸ ì‹œ ìƒì„± ì·¨ì†Œë¥¼ ëª…ì‹œ) ([ai.google.dev](https://ai.google.dev/gemini-api/docs/live-guide))
                    await ws.send(json.dumps({"type": "response.cancel"}))

        await asyncio.gather(sender(), receiver())

if __name__ == "__main__":
    asyncio.run(run())
```

í¬ì¸íŠ¸:
- â€œì‹¤ì‹œê°„â€ì€ **append(ì˜¤ë””ì˜¤ í”„ë ˆì„) â†’ delta(ì˜¤ë””ì˜¤ ì²­í¬)** ê°€ ëŠê¸°ì§€ ì•ŠëŠ” ê²Œ í•µì‹¬ì…ë‹ˆë‹¤.
- ì¸í„°ëŸ½íŠ¸ëŠ” â€œUIì—ì„œ ë²„íŠ¼â€ì´ ì•„ë‹ˆë¼ **VAD ì´ë²¤íŠ¸ë¥¼ íŠ¸ë¦¬ê±°ë¡œ** ìë™í™”í•´ì•¼ ì²´ê°ì´ ì¢‹ì•„ì§‘ë‹ˆë‹¤.
- ë¸Œë¼ìš°ì €/ëª¨ë°”ì¼ì´ë¼ë©´ WebRTCë¡œ ì˜®ê¸°ê³ , ì„œë²„ëŠ” ì¸ì¦/íˆ´ ì‹¤í–‰/ë¡œê¹…ë§Œ ë‹´ë‹¹ì‹œí‚¤ëŠ” êµ¬ì„±ì´ ì¼ë°˜ì ìœ¼ë¡œ ë” ë‚®ì€ ì§€ì—°ì„ ì–»ìŠµë‹ˆë‹¤. ([learn.microsoft.com](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/realtime-audio-webrtc))  

---

## âš¡ ì‹¤ì „ íŒ
1) **VAD hangover(ì¹¨ë¬µ íŒì •) íŠœë‹ì´ ëŒ€í™” ë¦¬ë“¬ì„ ì¢Œìš°**
- í„´ ì¢…ë£Œë¥¼ ë„ˆë¬´ ëŠ¦ê²Œ ì¡ìœ¼ë©´ ì‘ë‹µì´ ëŠë ¤ì§€ê³ ,
- ë„ˆë¬´ ë¹ ë¥´ê²Œ ì¡ìœ¼ë©´ ë§ì„ ëŠê³  ë¼ì–´ë“œëŠ” ëŠë‚Œì´ ë‚©ë‹ˆë‹¤.
- â€œì‚¬ìš©ì ë°œí™” ì‹œì‘â€ ê°ì§€ëŠ” ê³µê²©ì ìœ¼ë¡œ, â€œë°œí™” ì¢…ë£Œâ€ëŠ” ì•½ê°„ ë³´ìˆ˜ì ìœ¼ë¡œ(ì§§ì€ hangover) ê°€ì ¸ê°€ëŠ” ê²Œ ê²½í—˜ìƒ ì•ˆì •ì ì…ë‹ˆë‹¤.

2) **ì¬ìƒ ë²„í¼ëŠ” ì§§ê²Œ, ëŒ€ì‹  ëŠê¹€ ë³µêµ¬ ì „ëµì„**
- ë²„í¼ë¥¼ ê¸¸ê²Œ ì¡ì•„ ëŠê¹€ì„ ìˆ¨ê¸°ë©´ ì§€ì—°ì´ ì»¤ì ¸ UXê°€ ë§ê°€ì§‘ë‹ˆë‹¤.
- ì§§ì€ ë²„í¼ + íŒ¨í‚· ì†ì‹¤ ì‹œ â€œì§§ì€ ë¬´ìŒ/íƒ€ì„ìŠ¤íŠ¸ë ˆì¹˜â€ ê°™ì€ ì™„ì¶©ì„ ë‘ì„¸ìš”. (WebRTCê°€ ì´ ìª½ì— ê°•í•¨) ([learn.microsoft.com](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/realtime-audio-webrtc))  

3) **Tool callingì€ â€œìŒì„± í„´â€ê³¼ ë¶„ë¦¬í•´ì„œ ì„¤ê³„**
- ìŒì„± ì‘ë‹µì„ ê¸¸ê²Œ ëŒë©´ì„œ ì¤‘ê°„ì— DB/ì™¸ë¶€ APIë¥¼ ë•Œë¦¬ë©´ ì§€ì—°ì´ í­ë°œí•©ë‹ˆë‹¤.
- íŒ¨í„´ ì¶”ì²œ:
  - (a) ë¨¼ì € ì§§ê²Œ â€œí™•ì¸ ë©˜íŠ¸â€ë¥¼ ìŒì„±ìœ¼ë¡œ ë‚´ë³´ë‚´ê³ 
  - (b) ë°±ê·¸ë¼ìš´ë“œë¡œ íˆ´ ì‹¤í–‰
  - (c) ê²°ê³¼ê°€ ì˜¤ë©´ ë‹¤ìŒ í„´ì—ì„œ í™•ì • ë‹µë³€

4) **í†µí•©í˜• Voice Agent API vs BYO íŒŒì´í”„ë¼ì¸ ì„ íƒ ê¸°ì¤€**
- ë¹ ë¥¸ ì¶œì‹œ/ìš´ì˜ ë‹¨ìˆœí™”: í†µí•©í˜•(ì˜ˆ: Deepgram Voice Agent API GA) ([deepgram.com](https://deepgram.com/learn/voice-agent-api-generally-available))  
- ì»¤ìŠ¤í…€ ëª¨ë¸/ì •êµí•œ ì •ì±…/ì˜¨í”„ë ˆë¯¸ìŠ¤ ì œì•½: BYO íŒŒì´í”„ë¼ì¸(+SageMaker/ì‚¬ë‚´ ë°°í¬ ê²½ë¡œ) ([press.aboutamazon.com](https://press.aboutamazon.com/aws/2025/11/deepgram-launches-streaming-speech-text-and-voice-agents-on-amazon-sagemaker-ai?utm_source=openai))  

5) **â€œ3ì´ˆ ì§€ì—°â€ì˜ 80%ëŠ” ì§„ì§œ ëª¨ë¸ì´ ì•„ë‹ˆë¼ êµ¬í˜„**
- ì»¤ë®¤ë‹ˆí‹°ì—ì„œë„ end-to-end 3ì´ˆ+ëŠ” â€œë²„í¼ë§/ê°€ì§œ ìŠ¤íŠ¸ë¦¬ë°â€ì„ ì˜ì‹¬í•˜ë¼ëŠ” ì–˜ê¸°ê°€ ë°˜ë³µë©ë‹ˆë‹¤(ë¬¼ë¡  ê²½í—˜ë‹´ ìˆ˜ì¤€).  
- ì¸¡ì •ì€ ë°˜ë“œì‹œ êµ¬ê°„ë³„ë¡œ:
  - last user audio frame â†’ first server ack
  - VAD end â†’ first model audio delta
  - first delta â†’ speaker output

---

## ğŸš€ ë§ˆë¬´ë¦¬
2026ë…„ 2ì›”ì˜ ì‹¤ì‹œê°„ ìŒì„± ì—ì´ì „íŠ¸ëŠ” â€œSTT/TTS ë¶™ì´ë©´ ëâ€ì´ ì•„ë‹ˆë¼, **Streaming + VAD + Interrupt + Tool/State** ë¥¼ í•˜ë‚˜ì˜ ëŸ°íƒ€ì„ìœ¼ë¡œ ë‹¤ë£¨ëŠ” ì‹¸ì›€ì…ë‹ˆë‹¤.  
ì •ë¦¬í•˜ë©´:

- ì €ì§€ì—° ëª©í‘œë¼ë©´ **WebRTC ìš°ì„ **, WebSocketì€ ì„œë²„-ì„œë²„/ë‹¨ìˆœ ê²€ì¦ì— ì í•© ([learn.microsoft.com](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/realtime-audio-webrtc))  
- **ë¼ì–´ë“¤ê¸°(barge-in)** ëŠ” í•„ìˆ˜ ê¸°ëŠ¥ì´ë©°, VAD ê¸°ë°˜ cancelì´ í•µì‹¬ ([ai.google.dev](https://ai.google.dev/gemini-api/docs/live-guide))  
- í†µí•©í˜• Voice Agent APIê°€ â€œë³µì¡ë„/ì§€ì—°â€ì„ ì‹¤ì œë¡œ ì¤„ì—¬ì£¼ëŠ” êµ¬ê°„ì´ ìˆê³ (Deepgram), ì—”í„°í”„ë¼ì´ì¦ˆëŠ” ë°°í¬ ê²½ë¡œê¹Œì§€ ê°™ì´ ë´…ë‹ˆë‹¤. ([deepgram.com](https://deepgram.com/learn/voice-agent-api-generally-available))  

ë‹¤ìŒ í•™ìŠµ ì¶”ì²œ:
- WebRTC ê¸°ë°˜ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸(Opus, jitter buffer, echo cancellation)  
- ì´ë²¤íŠ¸ ê¸°ë°˜ Realtime API(ì„¸ì…˜/ëŒ€í™”/ì·¨ì†Œ/partial) ìƒíƒœ ë¨¸ì‹  ì„¤ê³„  
- ìŒì„± UX(í„´ ê¸¸ì´, ë°±ì±„ë„ë§ â€œë„¤/ì¢‹ì•„ìš”â€ ê°™ì€ ì§§ì€ ìŒì„± í† í°) ì‹¤í—˜

ì›í•˜ì‹œë©´, ìœ„ ì˜ˆì œë¥¼ **ë¸Œë¼ìš°ì €(WebRTC) + ì„œë²„(íˆ´ ì‹¤í–‰) + ìŒì„± ì¸í„°ëŸ½íŠ¸**ê¹Œì§€ í¬í•¨í•œ â€œí”„ë¡œë•ì…˜ ì•„í‚¤í…ì²˜â€ë¡œ í™•ì¥í•œ ë²„ì „(êµ¬ì„±ë„/ë©”íŠ¸ë¦­/ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸ í¬í•¨)ìœ¼ë¡œ ì´ì–´ì„œ ì‘ì„±í•´ë“œë¦´ê²Œìš”.
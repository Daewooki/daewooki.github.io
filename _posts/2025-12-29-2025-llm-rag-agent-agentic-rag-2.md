---
title: "2025ë…„í˜• LLM RAG Agent íŠœí† ë¦¬ì–¼: â€œê²€ìƒ‰ â†’ ê²€ì¦ â†’ ì¬ê²€ìƒ‰â€ê¹Œì§€ ìë™í™”í•˜ëŠ” Agentic RAG ì„¤ê³„/êµ¬í˜„"
date: 2025-12-29 02:27:19 +0900
categories: [AI, Tutorial]
tags: [ai, tutorial, trend, 2025-12]
---

## ë“¤ì–´ê°€ë©°
2024~2025ë…„ì— RAGë¥¼ ì‹¤ì œ ì„œë¹„ìŠ¤ì— ë¶™ì—¬ë³¸ íŒ€ë“¤ì´ ê³µí†µìœ¼ë¡œ ë¶€ë”ªíˆëŠ” ë²½ì´ ìˆìŠµë‹ˆë‹¤. **â€œVector searchë¡œ top-k ë½‘ê³  LLMì— ë„£ëŠ” ì„ í˜• íŒŒì´í”„ë¼ì¸â€**ì´ ìƒê°ë³´ë‹¤ ì‰½ê²Œ ë¬´ë„ˆì§„ë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì§ˆë¬¸ì´ ì• ë§¤í•˜ê±°ë‚˜, ë‹µì´ ì—¬ëŸ¬ ë¬¸ì„œì— í©ì–´ì ¸ ìˆê±°ë‚˜, ì²« ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì •í™•í•˜ë©´ ëª¨ë¸ì€ ê·¸ëŸ´ë“¯í•œ ë¬¸ì¥ì„ ë§Œë“¤ì–´ ë‚´ë©° ì‹¤íŒ¨í•©ë‹ˆë‹¤.

ê·¸ë˜ì„œ ìµœê·¼ íŠœí† ë¦¬ì–¼/í”„ë ˆì„ì›Œí¬ë“¤ì´ ê°•ì¡°í•˜ëŠ” ë°©í–¥ì€ **Agentic RAG**ì…ë‹ˆë‹¤. â€œê²€ìƒ‰â€ì„ í•œ ë²ˆ í•˜ê³  ëë‚´ëŠ” ê²Œ ì•„ë‹ˆë¼, **LLMì´ ë„êµ¬(tool)ë¥¼ ì‚¬ìš©í•´** ë‹¤ìŒì„ ë°˜ë³µ ìˆ˜í–‰í•©ë‹ˆë‹¤: (1) ì§ˆë¬¸ ì¬ì‘ì„±, (2) ë‹¤ì¤‘ ì†ŒìŠ¤ ì¡°íšŒ, (3) ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í‰ê°€, (4) í•„ìš” ì‹œ ì¬ê²€ìƒ‰/ê²½ë¡œ ë³€ê²½. LangChain/LangGraph, LlamaIndex Workflows ê°™ì€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ê°€ ì´ íë¦„ì„ ì „ì œë¡œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤. ([ibm.com](https://www.ibm.com/think/tutorials/agentic-rag?utm_source=openai))

---

## ğŸ”§ í•µì‹¬ ê°œë…
### 1) Agentic RAGì˜ ì •ì˜: â€œRetrieverë¥¼ Toolë¡œ ë§Œë“œëŠ” ìˆœê°„â€
ì „í†µ RAGëŠ” ëŒ€ê°œ ë‹¤ìŒ ê³ ì • íë¦„ì…ë‹ˆë‹¤.

- user query â†’ embedding â†’ vector DB ê²€ìƒ‰ â†’ top-k context â†’ LLM answer

Agentic RAGëŠ” ì—¬ê¸°ì„œ **Retrieverë¥¼ â€œí•„ìš”í•  ë•Œ í˜¸ì¶œí•˜ëŠ” Toolâ€**ë¡œ ë°”ê¿‰ë‹ˆë‹¤. ì¦‰, LLMì€ â€œì§€ê¸ˆì€ ë‹µì„ ì¨ì•¼ í• ì§€ / ë” ì°¾ì•„ì•¼ í• ì§€ / ì§ˆë¬¸ì„ ë°”ê¿”ì•¼ í• ì§€â€ë¥¼ íŒë‹¨í•˜ê³ , ê·¸ì— ë”°ë¼ tool callì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. IBMì˜ agentic RAG íŠœí† ë¦¬ì–¼ë„ â€œagentê°€ ì™¸ë¶€ ì •ë³´/ë„êµ¬ë¥¼ í™œìš©í•´ ë©€í‹°ìŠ¤í…ìœ¼ë¡œ ìê°€ ìˆ˜ì •í•œë‹¤â€ëŠ” ì ì„ ì „ë©´ì— ë‘¡ë‹ˆë‹¤. ([ibm.com](https://www.ibm.com/think/tutorials/agentic-rag?utm_source=openai))

### 2) í•µì‹¬ ë£¨í”„: Retrieve â†’ Grade â†’ (Rewrite | Generate)
2025ë…„í˜• êµ¬í˜„ì—ì„œ ê°€ì¥ ì‹¤ì „ì ì¸ íŒ¨í„´ì€ ì•„ë˜ 3ë‹¨ê³„ ë£¨í”„ì…ë‹ˆë‹¤.

1. **Retrieve**: ê²€ìƒ‰(ë²¡í„°/í‚¤ì›Œë“œ/ì›¹/DB ë“±)  
2. **Grade**: ê²€ìƒ‰ ê²°ê³¼ê°€ ì§ˆë¬¸ì— â€œì¶©ë¶„íˆ ê´€ë ¨ ìˆëŠ”ì§€â€ LLM/ê·œì¹™ìœ¼ë¡œ í‰ê°€  
3. **Rewrite or Generate**:  
   - ê´€ë ¨ì„±ì´ ë‚®ìœ¼ë©´: **query rewrite** í›„ ì¬ê²€ìƒ‰  
   - ê´€ë ¨ì„±ì´ ë†’ìœ¼ë©´: **ìµœì¢… ë‹µë³€ ìƒì„±**  

LangGraph ê¸°ë°˜ íŠœí† ë¦¬ì–¼ì—ì„œë„ retrieval í›„ â€œgrade_documentsâ€ ê°™ì€ ë…¸ë“œë¡œ relevanceë¥¼ íŒì •í•˜ê³ , routingìœ¼ë¡œ rewrite/generateë¥¼ ë¶„ê¸°í•˜ëŠ” êµ¬ì„±ì´ ëŒ€í‘œì ì…ë‹ˆë‹¤. ([medium.com](https://medium.com/%40mohitagr18/the-ai-that-thinks-before-it-searches-a-deep-dive-into-agentic-rag-82e5db9a0826?utm_source=openai))

### 3) Orchestration ë ˆì´ì–´ê°€ ì¤‘ìš”í•œ ì´ìœ : â€œì œì–´ ê°€ëŠ¥ì„±â€
Agentic RAGëŠ” í•„ì—°ì ìœ¼ë¡œ **ë£¨í”„/ë¶„ê¸°/ìƒíƒœ(state)**ê°€ ìƒê¹ë‹ˆë‹¤. ê·¸ë˜ì„œ í”„ë ˆì„ì›Œí¬ë„ â€œgraph/workflowâ€ í˜•íƒœë¡œ ì§„í™”í•©ë‹ˆë‹¤.

- **LlamaIndex Workflows**: event-driven stepìœ¼ë¡œ êµ¬ì„±í•˜ê³ , ìƒíƒœ/ì¬ì‹œë„/ê´€ì¸¡ì„±ì„ ì›Œí¬í”Œë¡œìš° ë‹¨ìœ„ë¡œ ë‹¤ë£¹ë‹ˆë‹¤. ë˜í•œ ìë™ instrumentë¡œ Phoenix ê°™ì€ observability ë„êµ¬ ì—°ë™ì„ ì–¸ê¸‰í•©ë‹ˆë‹¤. ([docs.llamaindex.ai](https://docs.llamaindex.ai/en/stable/module_guides/workflow/?utm_source=openai))  
- **LangGraph**: state graphë¡œ ë…¸ë“œë¥¼ êµ¬ì„±í•˜ê³ , tool í˜¸ì¶œê³¼ ì¡°ê±´ ë¶„ê¸°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ê³„í•  ìˆ˜ ìˆëŠ” ë°©í–¥ìœ¼ë¡œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤. ([medium.com](https://medium.com/%40mohitagr18/the-ai-that-thinks-before-it-searches-a-deep-dive-into-agentic-rag-82e5db9a0826?utm_source=openai))  

---

## ğŸ’» ì‹¤ì „ ì½”ë“œ
ì•„ë˜ëŠ” â€œê²€ìƒ‰ â†’ ê´€ë ¨ì„± í‰ê°€ â†’ (ì¬ê²€ìƒ‰ | ë‹µë³€)â€ì„ ìµœì†Œ êµ¬ì„±ìœ¼ë¡œ êµ¬í˜„í•œ **ì‹¤í–‰ ê°€ëŠ¥í•œ Python ì˜ˆì œ**ì…ë‹ˆë‹¤.  
ì „ì œ: ë¡œì»¬ì— ë¬¸ì„œê°€ ìˆê³ , Chromaì— ì¸ë±ì‹±í•œ ë’¤, LLMì´ **retriever tool**ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.

```python
# ì–¸ì–´: python
# pip install -U langchain langgraph langchain-openai chromadb tiktoken pydantic

import os
from typing import TypedDict, Literal, List

from pydantic import BaseModel, Field

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate

from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter

from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode, tools_condition

# -----------------------------
# 1) Data: ê°„ë‹¨ ë¬¸ì„œ ì…‹ì—… (ë°ëª¨)
# -----------------------------
docs = [
    Document(page_content="RAGëŠ” Retrieverë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ LLMì— ì»¨í…ìŠ¤íŠ¸ë¥¼ ì£¼ì…í•˜ëŠ” íŒ¨í„´ì´ë‹¤."),
    Document(page_content="Agentic RAGëŠ” LLMì´ toolì„ ì‚¬ìš©í•´ ê²€ìƒ‰/ì¬ê²€ìƒ‰/ê²€ì¦ì„ ë°˜ë³µí•˜ë©° self-correctí•œë‹¤."),
    Document(page_content="WorkflowsëŠ” event-driven stepìœ¼ë¡œ ë©€í‹°ìŠ¤í… ì—ì´ì „íŠ¸ë¥¼ êµ¬ì„±í•˜ê³  ê´€ì¸¡ì„±ì„ ì œê³µí•œë‹¤."),
]

splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=40)
chunks = splitter.split_documents(docs)

emb = OpenAIEmbeddings(model="text-embedding-3-small")  # í•„ìš” ì‹œ í™˜ê²½ì— ë§ê²Œ ë³€ê²½
vs = Chroma.from_documents(chunks, embedding=emb, persist_directory="./chroma_demo")
retriever = vs.as_retriever(search_kwargs={"k": 4})

# -----------------------------
# 2) Tool: Retrieverë¥¼ toolë¡œ ë…¸ì¶œ
# -----------------------------
@tool
def retrieve(query: str) -> str:
    """ë²¡í„° ìŠ¤í† ì–´ì—ì„œ queryì™€ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ ìš”ì•½ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•œë‹¤."""
    hits = retriever.get_relevant_documents(query)
    # ì‹¤ì „ì—ì„œëŠ” (chunk_id, source, page) ê°™ì€ metadataë¥¼ í•¨ê»˜ ë°˜í™˜í•˜ëŠ” ê²Œ ì¢‹ë‹¤.
    return "\n\n".join([f"- {d.page_content}" for d in hits])

tools = [retrieve]

# -----------------------------
# 3) LLM: ë„êµ¬ í˜¸ì¶œ + ì±„ì  ëª¨ë¸(êµ¬ì¡°í™” ì¶œë ¥)
# -----------------------------
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

class Grade(BaseModel):
    """retrieved contextê°€ ì§ˆë¬¸ì— ì¶©ë¶„íˆ ê´€ë ¨ ìˆëŠ”ì§€"""
    binary_score: Literal["yes", "no"] = Field(..., description="yes or no")

grader_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a strict relevance grader. Answer only with structured output."),
    ("user", "Question:\n{question}\n\nRetrieved Context:\n{context}\n\nIs the context relevant enough to answer?"),
])

rewrite_prompt = ChatPromptTemplate.from_messages([
    ("system", "Rewrite the user question to improve retrieval. Keep it short and specific."),
    ("user", "{question}"),
])

answer_prompt = ChatPromptTemplate.from_messages([
    ("system", "Answer using ONLY the provided context. If missing, say you don't know."),
    ("user", "Question:\n{question}\n\nContext:\n{context}"),
])

# -----------------------------
# 4) LangGraph State + Nodes
# -----------------------------
class State(TypedDict):
    question: str
    context: str
    attempts: int
    answer: str

MAX_ATTEMPTS = 2

def agent_decide(state: State):
    """
    LLMì´ toolì„ ì“¸ì§€ ë§ì§€ ê²°ì •.
    ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ í•­ìƒ retrieve toolì„ í˜¸ì¶œí•˜ë„ë¡ ìœ ë„í•œë‹¤.
    """
    model = llm.bind_tools(tools)
    msg = model.invoke([("user", f"Use the retrieve tool to fetch context for: {state['question']}")])
    return {"messages": [msg]}

def grade_context(state: State) -> dict:
    graded = llm.with_structured_output(Grade).invoke(
        grader_prompt.format_messages(question=state["question"], context=state["context"])
    )
    # yesë©´ generate, noë©´ rewrite
    route = "generate" if graded.binary_score == "yes" else "rewrite"
    return {"route": route}

def rewrite_query(state: State) -> State:
    new_q = llm.invoke(rewrite_prompt.format_messages(question=state["question"])).content
    return {**state, "question": new_q, "attempts": state["attempts"] + 1}

def generate_answer(state: State) -> State:
    ans = llm.invoke(answer_prompt.format_messages(question=state["question"], context=state["context"])).content
    return {**state, "answer": ans}

# ToolNode ì‹¤í–‰ ê²°ê³¼ì—ì„œ contextë¥¼ Stateì— ì ì¬í•˜ê¸° ìœ„í•œ í›„ì²˜ë¦¬
def extract_context(state) -> dict:
    # ToolNodeê°€ messagesì— tool outputì„ ë„£ì–´ì¤€ë‹¤. ì—¬ê¸°ì„œëŠ” ë§ˆì§€ë§‰ messageë¥¼ contextë¡œ ê°„ì£¼(ë°ëª¨).
    last = state["messages"][-1]
    # LangChain message êµ¬ì¡°ì— ë”°ë¼ content ì ‘ê·¼ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´, ì‹¤ì „ì—ì„  íƒ€ì… ì²´í¬ í•„ìš”
    return {"context": getattr(last, "content", str(last))}

# -----------------------------
# 5) Graph Wiring
# -----------------------------
g = StateGraph(State)

# ë…¸ë“œ ë“±ë¡
g.add_node("agent", agent_decide)
g.add_node("tools", ToolNode(tools))
g.add_node("extract_context", extract_context)
g.add_node("rewrite", rewrite_query)
g.add_node("generate", generate_answer)

# íë¦„: agent -> tools (tool call) -> extract_context -> grade -> (rewrite|generate)
g.add_edge(START, "agent")
g.add_conditional_edges("agent", tools_condition, {"tools": "tools", END: END})
g.add_edge("tools", "extract_context")

def route_after_grade(state: State) -> str:
    # attempts ì´ˆê³¼ë©´ generateë¡œ ê°•ì œ ì¢…ë£Œ(ë¬´í•œë£¨í”„ ë°©ì§€)
    if state["attempts"] >= MAX_ATTEMPTS:
        return "generate"
    # grade_contextì—ì„œ routeë¥¼ ê³„ì‚°
    route = grade_context(state)["route"]
    return route

g.add_conditional_edges("extract_context", route_after_grade, {"rewrite": "rewrite", "generate": "generate"})
g.add_edge("rewrite", "agent")
g.add_edge("generate", END)

app = g.compile()

if __name__ == "__main__":
    init: State = {"question": "2025ë…„ ê¸°ì¤€ Agentic RAGê°€ ë­ê³  ì™œ ì“°ë‚˜?", "context": "", "attempts": 0, "answer": ""}
    out = app.invoke(init)
    print(out["answer"])
```

ì´ ì˜ˆì œì˜ í¬ì¸íŠ¸ëŠ” â€œRAGâ€ ìì²´ê°€ ì•„ë‹ˆë¼ **RAGë¥¼ ì œì–´í•˜ëŠ” ë£¨í”„**ì…ë‹ˆë‹¤. ì‹¤ì „ì—ì„œëŠ” `grade_context`ë¥¼ ë” ì •êµí•˜ê²Œ ë§Œë“¤ì–´(ì˜ˆ: evidence coverage, contradiction ê²€ì‚¬, citation í•„ìˆ˜í™”), â€œê²€ìƒ‰ ê²°ê³¼ê°€ ë‚˜ì˜ë©´ ë‹¤ì‹œ ì°¾ëŠ”ë‹¤â€ê°€ ì‹¤ì œë¡œ ë™ì‘í•˜ë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤.

---

## âš¡ ì‹¤ì „ íŒ
1) **ë¬´í•œ ë£¨í”„ ë°©ì§€**ëŠ” ê¸°ëŠ¥ì´ ì•„ë‹ˆë¼ â€œì•ˆì „ì¥ì¹˜â€
Agentic RAGëŠ” ì˜ ì„¤ê³„í•˜ì§€ ì•Šìœ¼ë©´ â€œrewriteâ†’retrieveâ†’rewriteâ€¦â€ë¡œ ë¹„ìš©ë§Œ íƒœì›ë‹ˆë‹¤. ìœ„ ì½”ë“œì²˜ëŸ¼ `MAX_ATTEMPTS`ë¥¼ ë‘ê³ , ì´ˆê³¼ ì‹œ fallback ì‘ë‹µ(â€œê·¼ê±° ë¶€ì¡±â€)ìœ¼ë¡œ ì¢…ë£Œí•˜ì„¸ìš”. LangGraph/LlamaIndex Workflows ëª¨ë‘ ë£¨í”„/ë¶„ê¸°ë¥¼ ì „ì œë¡œ í•˜ì§€ë§Œ, ì¢…ë£Œ ì¡°ê±´ì€ ê°œë°œìê°€ ì±…ì„ì ¸ì•¼ í•©ë‹ˆë‹¤. ([medium.com](https://medium.com/%40mohitagr18/the-ai-that-thinks-before-it-searches-a-deep-dive-into-agentic-rag-82e5db9a0826?utm_source=openai))

2) **Grade(í‰ê°€) ë…¸ë“œê°€ ì„±ëŠ¥ì„ ì¢Œìš°í•œë‹¤**
ëŒ€ë¶€ë¶„ íŒ€ì´ â€œRetriever íŠœë‹â€ì—ë§Œ ëª°ì…í•˜ëŠ”ë°, Agentic RAGì—ì„  **retrieval ì´í›„ì˜ í’ˆì§ˆ í‰ê°€(grade)**ê°€ ë³‘ëª©ì…ë‹ˆë‹¤.
- yes/no ì´ì§„ ë¶„ê¸°ë§Œìœ¼ë¡œ ë¶€ì¡±í•˜ë©´:  
  - `relevance_score`(0~1),  
  - `coverage`(ì§ˆë¬¸ í•˜ìœ„ìš”ì†Œ ì¶©ì¡± ì—¬ë¶€),  
  - `need_more_sources` ê°™ì€ í•„ë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”(êµ¬ì¡°í™” ì¶œë ¥ ê°•ì œ).

3) **RAGëŠ” â€˜chunkâ€™ê°€ ì•„ë‹ˆë¼ â€˜contextâ€™ë¥¼ ì„¤ê³„í•˜ëŠ” ì¼**
LlamaIndex ìª½ì—ì„œë„ ë¬¸ì„œ ì²˜ë¦¬/ì›Œí¬í”Œë¡œìš°ë¥¼ ê°•ì¡°í•˜ëŠ” íë¦„ì´ ê°•í•©ë‹ˆë‹¤. ë‹¨ìˆœ splitì´ ì•„ë‹ˆë¼ â€œë¬¸ì„œë¥¼ AI-friendlyí•˜ê²Œ ë³€í™˜í•˜ê³ , ì—ì´ì „íŠ¸ê°€ ì“°ê¸° ì¢‹ì€ í˜•íƒœë¡œ ì œê³µâ€í•˜ëŠ” ìª½ì´ 2025ë…„ì˜ ì‹¤ì „ í¬ì¸íŠ¸ì…ë‹ˆë‹¤. ([docs.llamaindex.ai](https://docs.llamaindex.ai/en/stable/understanding/?utm_source=openai))

4) **Observability ì—†ìœ¼ë©´ ê°œì„  ë¶ˆê°€ëŠ¥**
Agentic RAGëŠ” ë…¸ë“œê°€ ëŠ˜ê³  ê²½ë¡œê°€ ë¶„ê¸°ë˜ê¸° ë•Œë¬¸ì—, â€œì™œ ì‹¤íŒ¨í–ˆëŠ”ì§€â€ë¥¼ ì¶”ì í•˜ì§€ ëª»í•˜ë©´ ìš´ì˜ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. LlamaIndex WorkflowsëŠ” ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ ê´€ì¸¡ì„±(ì˜ˆ: Phoenix ì—°ë™)ì„ ë¬¸ì„œì—ì„œ ì–¸ê¸‰í•©ë‹ˆë‹¤. ([docs.llamaindex.ai](https://docs.llamaindex.ai/en/stable/module_guides/workflow/?utm_source=openai))  
ìµœì†Œí•œ ë‹¤ìŒì€ ë¡œê¹…/íŠ¸ë ˆì´ì‹±í•˜ì„¸ìš”:
- query rewrite ì „/í›„
- retrieval top-kì™€ ì ìˆ˜
- grade ê²°ê³¼
- ìµœì¢… answerê°€ ì°¸ì¡°í•œ ê·¼ê±° ëª©ë¡

---

## ğŸš€ ë§ˆë¬´ë¦¬
2025ë…„í˜• RAG êµ¬í˜„ì˜ í•µì‹¬ì€ â€œVector DB ë¶™ì´ê¸°â€ê°€ ì•„ë‹ˆë¼, **LLMì´ ê²€ìƒ‰ì„ â€˜ë„êµ¬â€™ë¡œ ì“°ë©° ìŠ¤ìŠ¤ë¡œ ê²½ë¡œë¥¼ ë°”ê¾¸ëŠ” ì œì–´ êµ¬ì¡°(loops/branches/state)**ë¥¼ ì„¤ê³„í•˜ëŠ” ë° ìˆìŠµë‹ˆë‹¤. Agentic RAGë¥¼ ë„ì…í•˜ë©´, ì• ë§¤í•œ ì§ˆë¬¸Â·ì €í’ˆì§ˆ ê²€ìƒ‰ ê²°ê³¼Â·ë‹¤ì¤‘ ë¬¸ì„œ ì¢…í•© ê°™ì€ ì‹¤ì œ ë¬¸ì œì—ì„œ í›¨ì”¬ ê²¬ê³ í•´ì§‘ë‹ˆë‹¤. ([ibm.com](https://www.ibm.com/think/tutorials/agentic-rag?utm_source=openai))

ë‹¤ìŒ í•™ìŠµ ì¶”ì²œ(ìˆœì„œ):
- LangGraphë¡œ â€œRetrieveâ†’Gradeâ†’Rewriteâ€ ê·¸ë˜í”„ë¥¼ 2~3ê°€ì§€ ë³€í˜•ìœ¼ë¡œ ë§Œë“¤ì–´ ë³´ê¸° ([medium.com](https://medium.com/%40mohitagr18/the-ai-that-thinks-before-it-searches-a-deep-dive-into-agentic-rag-82e5db9a0826?utm_source=openai))  
- LlamaIndex Workflowsë¡œ ë™ì¼ íŒ¨í„´ì„ event-driven stepìœ¼ë¡œ ì¬êµ¬í˜„í•˜ë©° ê´€ì¸¡ì„±/ì¬ì‹œë„/ìƒíƒœ ê´€ë¦¬ë¥¼ ìµíˆê¸° ([docs.llamaindex.ai](https://docs.llamaindex.ai/en/stable/module_guides/workflow/?utm_source=openai))  
- ë§ˆì§€ë§‰ìœ¼ë¡œ, grade ê¸°ì¤€ì„ ì œí’ˆ KPI(ì •ë‹µë¥ /ê·¼ê±° í¬í•¨ë¥ /ë¹„ìš©/latency)ì— ë§ì¶° ìˆ˜ì¹˜í™”í•˜ê³  ì‹¤í—˜ ë£¨í”„ë¥¼ ëŒë¦¬ê¸° (ì—¬ê¸°ì„œë¶€í„°ê°€ â€œì§„ì§œ RAG ì—”ì§€ë‹ˆì–´ë§â€ì…ë‹ˆë‹¤)

ì›í•˜ì‹œë©´ ìœ„ ì˜ˆì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ **(1) ë‹¤ì¤‘ retriever ë¼ìš°íŒ…**, **(2) citation ê°•ì œ + ê·¼ê±° ë¶€ì¡± ì‹œ â€œëª¨ë¥¸ë‹¤â€ ì •ì±…**, **(3) Phoenix/OTel íŠ¸ë ˆì´ì‹± í¬í•¨** ë²„ì „ìœ¼ë¡œ í™•ì¥í•œ ì½”ë“œê¹Œì§€ ì´ì–´ì„œ ì •ë¦¬í•´ë“œë¦´ê²Œìš”.
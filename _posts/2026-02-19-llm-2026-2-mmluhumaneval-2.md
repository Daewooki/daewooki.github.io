---
title: "LLM ì„±ëŠ¥í‰ê°€ì˜ í•¨ì •: 2026ë…„ 2ì›” ê¸°ì¤€ MMLUÂ·HumanEval ë²¤ì¹˜ë§ˆí¬ë¥¼ â€œìˆ«ìâ€ê°€ ì•„ë‹ˆë¼ â€œë°©ë²•â€ìœ¼ë¡œ ì½ëŠ” ë²•"
date: 2026-02-19 02:50:15 +0900
categories: [AI, LLM]
tags: [ai, llm, trend, 2026-02]
---

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7990TVG7C7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7990TVG7C7');
</script>

## ë“¤ì–´ê°€ë©°
LLMì„ ë°°í¬/ìš´ì˜í•˜ëŠ” ì…ì¥ì—ì„œ â€œìš°ë¦¬ ëª¨ë¸ì´ ë” ë˜‘ë˜‘í•´ì¡Œë‹¤â€ë¥¼ ì¦ëª…í•˜ëŠ” ê°€ì¥ ì‰¬ìš´ ë°©ë²•ì€ MMLU, HumanEval ê°™ì€ ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ë‹ˆë‹¤. ë¬¸ì œëŠ” **ì ìˆ˜ëŠ” ì‰¬ìš´ë°, í•´ì„ì€ ì–´ë µë‹¤**ëŠ” ê²ƒ. ê°™ì€ ëª¨ë¸ì´ë¼ë„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, few-shot ê°œìˆ˜, ì¶œë ¥ í˜•ì‹ ê°•ì œ, sampling íŒŒë¼ë¯¸í„°, ì‹¬ì§€ì–´ í‰ê°€ ë„êµ¬ ë²„ì „ì´ ë‹¬ë¼ì§€ë©´ ì ìˆ˜ê°€ í”ë“¤ë¦½ë‹ˆë‹¤. ì‹¤ì œë¡œ í˜„ì—…ì—ì„œ â€œë¦¬ê·¸í…Œì´ë¸” 1ë“±â€ì´ ì œí’ˆ í’ˆì§ˆì„ ë³´ì¥í•˜ì§€ ì•ŠëŠ” ì´ìœ ì˜ ëŒ€ë¶€ë¶„ì€ **í‰ê°€ í”„ë¡œí† ì½œì˜ ì°¨ì´**ì—ì„œ ë‚˜ì˜µë‹ˆë‹¤.

2026ë…„ 2ì›” ì‹œì ì—” EleutherAIì˜ `lm-evaluation-harness`ê°€ ì‚¬ì‹¤ìƒ í‘œì¤€ ì‹¤í–‰ê¸° ì—­í• ì„ í•˜ê³  ìˆê³ (ìµœê·¼ ë¦´ë¦¬ìŠ¤ê°€ ê³„ì† ê°±ì‹ ), MMLUëŠ” ë³€í˜• íƒœìŠ¤í¬(ì˜ˆ: logits ê¸°ë°˜, instruct ê°•ì œ)ê°€ ëŠ˜ì–´ë‚˜ë©´ì„œ **â€˜MMLU ì ìˆ˜â€™ë¼ëŠ” ë§ ìì²´ê°€ ëª¨í˜¸**í•´ì¡ŒìŠµë‹ˆë‹¤. ([github.com](https://github.com/EleutherAI/lm-evaluation-harness/releases))

---

## ğŸ”§ í•µì‹¬ ê°œë…
### 1) MMLUëŠ” â€œì§€ì‹+ì¶”ë¡ â€ì„ ë¬»ì§€ë§Œ, ë¬´ì—‡ì„ ê°•ì œí•˜ëŠëƒê°€ ì ìˆ˜ë¥¼ ë§Œë“ ë‹¤
`lm-evaluation-harness` ìª½ ì¹´íƒˆë¡œê·¸ë¥¼ ë³´ë©´ MMLU ê³„ì—´ì´ ì—¬ëŸ¬ ë³€ì¢…ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ:
- `mmlu`: ê¸°ë³¸ MMLU(57 subjects) ([docs.nvidia.com](https://docs.nvidia.com/nemo/evaluator/latest/evaluation/benchmarks/catalog/all/harnesses/lm-evaluation-harness.html))  
- `mmlu_instruct`: **ì¶œë ¥ì„ ë‹¨ì¼ ì•ŒíŒŒë²³(letter)**ë¡œ ê°•ì œí•˜ëŠ” ë³€í˜•(ì±„ì  ì•ˆì •ì„± â†‘, ëŒ€ì‹  ì‹¤ì œ ì±—ëª¨ë¸ í–‰íƒœì™€ ê´´ë¦¬ ê°€ëŠ¥) ([docs.nvidia.com](https://docs.nvidia.com/nemo/evaluator/latest/evaluation/benchmarks/catalog/all/harnesses/lm-evaluation-harness.html))  
- `mmlu_logits`: **ìƒì„± í…ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ logitsë¡œ ì •ë‹µ ì„ íƒ**(ëª¨ë¸ì´ â€œì„¤ëª… ì˜í•˜ë‹¤ê°€ ë§ˆì§€ë§‰ì— í—›ì†Œë¦¬â€ í•˜ëŠ” ë¬¸ì œë¥¼ ì œê±°í•˜ì§€ë§Œ, API ëª¨ë¸ì€ logprobs ë¯¸ì§€ì›ì´ë©´ í‰ê°€ ë¶ˆê°€) ([docs.nvidia.com](https://docs.nvidia.com/nemo/evaluator/latest/evaluation/benchmarks/catalog/all/harnesses/lm-evaluation-harness.html))  
- `mmlu_pro`: MMLU-Pro(â€œë” ì–´ë µê²Œâ€ ë§Œë“¤ê¸° ìœ„í•´ ì„ íƒì§€ ìˆ˜ë¥¼ ëŠ˜ë¦° ë²„ì „ìœ¼ë¡œ ì•Œë ¤ì§) ([docs.nvidia.com](https://docs.nvidia.com/nemo/evaluator/latest/evaluation/benchmarks/catalog/all/harnesses/lm-evaluation-harness.html))  

ì—¬ê¸°ì„œ ì¤‘ìš”í•œ í•´ì„ í¬ì¸íŠ¸ëŠ”:
- **ìƒì„± ê¸°ë°˜(letter ì¶œë ¥)**ì€ â€œëª¨ë¸ì´ ì§€ì‹ì´ ìˆë‚˜?â€ + â€œì§€ì‹œë¥¼ ì˜ ë”°ë¥´ë‚˜?â€ê°€ ì„ì…ë‹ˆë‹¤.
- **logits ê¸°ë°˜**ì€ â€œëª¨ë¸ ë‚´ë¶€ ë¶„í¬ê°€ ì •ë‹µì„ ë” ì„ í˜¸í•˜ë‚˜?â€ì— ê°€ê¹ìŠµë‹ˆë‹¤.
- ë”°ë¼ì„œ MMLU ì ìˆ˜ë¥¼ ë¹„êµí•  ë•ŒëŠ” â€œMMLUâ€ê°€ ì•„ë‹ˆë¼ **(íƒœìŠ¤í¬ ë³€í˜•, few-shot, chat template ì ìš© ì—¬ë¶€)**ê¹Œì§€ ê°™ì´ ì ì–´ì•¼ ì¬í˜„ë©ë‹ˆë‹¤.

ì¶”ê°€ë¡œ MMLU-Proë„ ê¹”ë”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„° ì¹´ë“œ/ë…¼ì˜ì—ì„œ â€œí•­ìƒ 10 choicesâ€ë¼ê³  ìƒê°í–ˆëŠ”ë° ì‹¤ì œ splitì—ì„  ì„ íƒì§€ ê°œìˆ˜ê°€ ê°€ë³€(3~10)ì¸ í•­ëª©ì´ ì¡´ì¬í•˜ë©°, ì´ëŠ” í•„í„°ë§/í’ˆì§ˆê´€ë¦¬ ê³¼ì • ë•Œë¬¸ì´ë¼ê³  ì„¤ëª…ë©ë‹ˆë‹¤. ì¦‰, â€œ10ì§€ì„ ë‹¤ë¼ì„œ guess í™•ë¥ ì´ ë‚®ë‹¤â€ ê°™ì€ ë‹¨ìˆœí•œ ì„œìˆ ë§Œ ë¯¿ê³  ë‚œì´ë„ë¥¼ ë‹¨ì •í•˜ë©´ ìœ„í—˜í•©ë‹ˆë‹¤. ([huggingface.co](https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro/discussions/22))

### 2) HumanEvalì€ â€œì½”ë“œ í˜•íƒœâ€ê°€ ì•„ë‹ˆë¼ â€œì‹¤í–‰ ê²°ê³¼(Functional Correctness)â€ë¥¼ ë³¸ë‹¤
HumanEvalì€ 164ê°œ ë¬¸ì œì—ì„œ **docstring(ìš”êµ¬ì‚¬í•­) â†’ Python í•¨ìˆ˜ ì½”ë“œ ìƒì„± â†’ ìˆ¨ê²¨ì§„ unit test í†µê³¼ ì—¬ë¶€**ë¡œ ì¸¡ì •í•©ë‹ˆë‹¤. ([deepwiki.com](https://deepwiki.com/EleutherAI/lm-evaluation-harness/3.4-code-generation-tasks?utm_source=openai))  
í•µì‹¬ì€ â€œê·¸ëŸ´ë“¯í•œ ì½”ë“œâ€ê°€ ì•„ë‹ˆë¼ **í…ŒìŠ¤íŠ¸ í†µê³¼**ì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì‹¤í–‰ ê¸°ë°˜ í‰ê°€ë¼ì„œ ë‹¤ìŒì´ ì„±íŒ¨ë¥¼ ê°€ë¦…ë‹ˆë‹¤:
- í”„ë¡¬í”„íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ëŠëƒ(ê³µë°±/íŠ¸ë ì¼€ì´ì…˜/í…œí”Œë¦¿ ì‚½ì…)
- ëª¨ë¸ ì¶œë ¥ì—ì„œ â€œì„¤ëª… í…ìŠ¤íŠ¸â€ë¥¼ í—ˆìš©í•˜ëŠëƒ(ì½”ë“œë§Œ íŒŒì‹±í•˜ëŠëƒ)
- ìƒŒë“œë°•ìŠ¤/íƒ€ì„ì•„ì›ƒ/ì˜ì¡´ì„± ì°¨ì´

ì‹¤ì œë¡œ HumanEval ì‹¤í–‰ê¸° êµ¬í˜„ì—ì„œ `unsafe_code: true`ì²˜ëŸ¼ **ì½”ë“œ ì‹¤í–‰ ìì²´ê°€ í•„ìˆ˜ì´ë©° ë³´ì•ˆ ë¦¬ìŠ¤í¬**ê°€ ë™ë°˜ëœë‹¤ëŠ” ì ì´ ëª…ì‹œë©ë‹ˆë‹¤. ([deepwiki.com](https://deepwiki.com/EleutherAI/lm-evaluation-harness/3.4-code-generation-tasks?utm_source=openai))

### 3) pass@këŠ” í¸í•˜ì§€ë§Œ, â€œìƒ˜í”Œë§ ì •ì±…â€ì´ ê³§ ì ìˆ˜ë‹¤
HumanEvalì€ ì¢…ì¢… `pass@1`, `pass@k`ë¥¼ ì”ë‹ˆë‹¤. pass@këŠ” â€œkë²ˆ ë½‘ì•„ í•˜ë‚˜ë¼ë„ ë§ìœ¼ë©´ ì„±ê³µâ€ í™•ë¥ ì´ë¼ì„œ, temperature/íƒìƒ‰ ì •ì±…ì´ ë°”ë€Œë©´ ì ìˆ˜ê°€ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ([emergentmind.com](https://www.emergentmind.com/topics/humaneval-dataset?utm_source=openai))  
ê²Œë‹¤ê°€ 2025ë…„ì—” pass@kê°€ ë­í‚¹ì„ ë¶ˆì•ˆì •í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆë‹¤ëŠ” ë¹„íŒê³¼ í•¨ê»˜ Bayesian ê´€ì ì˜ ëŒ€ì•ˆ í”„ë ˆì„ì›Œí¬ë„ ì œì•ˆë©ë‹ˆë‹¤(ìƒ˜í”Œ ìˆ˜ê°€ ì œí•œë ìˆ˜ë¡ ë” ë¬¸ì œ). ([arxiv.org](https://arxiv.org/abs/2510.04265?utm_source=openai))

ì •ë¦¬í•˜ë©´:
- **MMLUëŠ” â€œì±„ì  ë°©ì‹â€ì´ ì ìˆ˜ë¥¼ ë§Œë“ ë‹¤**
- **HumanEvalì€ â€œì‹¤í–‰ í™˜ê²½/íŒŒì„œ/ìƒ˜í”Œë§â€ì´ ì ìˆ˜ë¥¼ ë§Œë“ ë‹¤**
- ë”°ë¼ì„œ ë²¤ì¹˜ë§ˆí¬ëŠ” ë‹¨ì¼ ìˆ«ìê°€ ì•„ë‹ˆë¼ **í”„ë¡œí† ì½œì˜ ë¬¶ìŒ**ìœ¼ë¡œ ì½ì–´ì•¼ í•©ë‹ˆë‹¤.

---

## ğŸ’» ì‹¤ì „ ì½”ë“œ
ì•„ë˜ëŠ” `lm-evaluation-harness(lm_eval)`ë¡œ MMLU/HumanEvalì„ **ì¬í˜„ ê°€ëŠ¥í•˜ê²Œ** ëŒë¦¬ëŠ” ìµœì†Œ ì˜ˆì œì…ë‹ˆë‹¤. í•µì‹¬ì€ â€œì‹¤í–‰ ì»¤ë§¨ë“œâ€ë³´ë‹¤ **ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥í•˜ê³ , ì‹¤í–‰ ì¡°ê±´ì„ ê°™ì´ ë²„ì „ê´€ë¦¬**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. (ìµœê·¼ ë¦´ë¦¬ìŠ¤ì—ì„œ ë°±ì—”ë“œê°€ ì„ íƒ ì„¤ì¹˜ë¡œ ë°”ë€ŒëŠ” ë“± í™˜ê²½ ì°¨ì´ê°€ ì»¤ì¡ŒìŠµë‹ˆë‹¤.) ([github.com](https://github.com/EleutherAI/lm-evaluation-harness/releases))

```bash
# 1) ì„¤ì¹˜ (core + HF backend ì˜ˆì‹œ)
python -m venv .venv
source .venv/bin/activate

pip install -U pip
pip install "lm_eval" "transformers" "torch"

# 2) MMLU í‰ê°€ (instruct variant: letter ì¶œë ¥ ê°•ì œ)
# - apply_chat_template ì—¬ë¶€ê°€ instruct ëª¨ë¸ ì ìˆ˜ì— í° ì˜í–¥
# - num_fewshot(0/5/10 ë“±)ë„ ë°˜ë“œì‹œ ëª…ì‹œ
lm_eval \
  --model hf \
  --model_args pretrained=meta-llama/Llama-2-7b-hf \
  --tasks mmlu_instruct \
  --apply_chat_template \
  --num_fewshot 5 \
  --batch_size 4 \
  --output_path ./runs/mmlu_instruct_f5.json

# 3) HumanEval í‰ê°€
# - HumanEvalì€ ì½”ë“œ ì‹¤í–‰ì´ í•„ìš”(ì‹¤í–‰í™˜ê²½/ìƒŒë“œë°•ìŠ¤ ì£¼ì˜)
# - pass@1ì„ ìš°ì„  ê³ ì •(ìƒ˜í”Œë§ ì˜í–¥ ìµœì†Œí™”) í›„ pass@k í™•ì¥ ê¶Œì¥
lm_eval \
  --model hf \
  --model_args pretrained=meta-llama/Llama-2-7b-hf \
  --tasks humaneval \
  --batch_size 1 \
  --output_path ./runs/humaneval_pass1.json
```

ì‹¤ë¬´ì—ì„œëŠ” JSON ê²°ê³¼ íŒŒì¼ì— ë”í•´ ì•„ë˜ë¥¼ ê°™ì´ ë‚¨ê¸°ì„¸ìš”.
- `lm_eval --version`(ë˜ëŠ” íŒ¨í‚¤ì§€ lock)
- ëª¨ë¸ í•´ì‹œ/ë¦¬ë¹„ì „
- í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿(system prompt í¬í•¨)
- decoding íŒŒë¼ë¯¸í„°(temperature, top_p, max_new_tokens)
- HumanEval ì‹¤í–‰ ì»¨í…Œì´ë„ˆ/íŒŒì´ì¬ ë²„ì „/íƒ€ì„ì•„ì›ƒ

---

## âš¡ ì‹¤ì „ íŒ
1) **â€œMMLU ì ìˆ˜â€ë¼ê³  ë§í•˜ì§€ ë§ê³ , ë³€í˜•/ì„¤ì •ì„ ê°™ì´ ë§í•˜ë¼**
- ì˜ˆ: `mmlu_instruct, 5-shot, chat template on` ê°™ì´ ê¸°ë¡.
- logits ê¸°ë°˜(`mmlu_logits`)ì€ í•´ì„ì´ ë” â€œëª¨ë¸ ìì²´ ëŠ¥ë ¥â€ì— ê°€ê¹ì§€ë§Œ, í”Œë«í¼ ì œì•½(ì˜ˆ: logprobs ë¯¸ì§€ì›)ìœ¼ë¡œ ì¬í˜„ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ([docs.nvidia.com](https://docs.nvidia.com/nemo/microservices/latest/evaluate/evaluation-types.html?utm_source=openai))

2) **HumanEvalì€ íŒŒì„œ/í¬ë§· ê·œì¹™ì´ ì€ê·¼íˆ ì ìˆ˜ë¥¼ ì¢Œìš°í•œë‹¤**
- â€œì„¤ëª… + ì½”ë“œâ€ë¥¼ í—ˆìš©í•˜ëƒ, fenced codeë§Œ ë°›ëƒì— ë”°ë¼ í†µê³¼ìœ¨ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤.
- í”„ë¡¬í”„íŠ¸ë¥¼ â€œì›ë¬¸ ê·¸ëŒ€ë¡œâ€ ìœ ì§€í•˜ëŠ” ëŸ¬ë„ˆ(ì¶œë ¥/ì‹¤íŒ¨ ì‚¬ìœ  ì €ì¥)ì²˜ëŸ¼ **ê°ì‚¬(audit)** ê°€ëŠ¥í•œ í˜•íƒœê°€ ì‹ ë¢°ë„ë¥¼ ì˜¬ë¦½ë‹ˆë‹¤. ([pypi.org](https://pypi.org/project/gguf-humaneval-benchmark/?utm_source=openai))

3) **pass@këŠ” â€˜ëª¨ë¸â€™ ì„±ëŠ¥ì´ë¼ê¸°ë³´ë‹¤ â€˜ìƒ˜í”Œë§+ì˜ˆì‚°â€™ ì„±ëŠ¥ì´ë‹¤**
- pass@1ì„ ê¸°ë³¸ KPIë¡œ ë‘ê³ ,
- pass@këŠ” â€œë™ì¼í•œ ìƒ˜í”Œ ìˆ˜(n), ë™ì¼í•œ decodingâ€ìœ¼ë¡œë§Œ ë¹„êµí•˜ì„¸ìš”.
- ìƒ˜í”Œ ìˆ˜ê°€ ì‘ë‹¤ë©´ pass@k ë­í‚¹ì´ ì¶œë ì¼ ìˆ˜ ìˆë‹¤ëŠ” ë¬¸ì œ ì œê¸°ë„ ìˆìœ¼ë‹ˆ, ìµœì†Œí•œ ì‹ ë¢°êµ¬ê°„/ë°˜ë³µ ì¸¡ì •ì„ ê°™ì´ ì œì‹œí•˜ëŠ” ê²Œ ì¢‹ìŠµë‹ˆë‹¤. ([arxiv.org](https://arxiv.org/abs/2510.04265?utm_source=openai))

4) **HumanEval ê³ ë“ì ì´ ê³§ â€˜ì½”ë“œ ì´í•´â€™ëŠ” ì•„ë‹ˆë‹¤**
- HumanEvalì€ â€œí•¨ìˆ˜ ì‘ì„±â€ì— ê°•í•˜ì§€ë§Œ, ì§§ì€ ì½”ë“œì˜ ì‹¤í–‰ ì¶”ë¡ /ì…ì¶œë ¥ ì˜ˆì¸¡ ê°™ì€ ë‹¤ë¥¸ ì¶•ì—ì„  ìƒê´€ì´ ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì˜ˆ: CRUXEvalì´ ë³´ì—¬ì£¼ëŠ” ê´´ë¦¬). ([arxiv.org](https://arxiv.org/abs/2401.03065?utm_source=openai))  
ì¦‰, ì œí’ˆì´ ìš”êµ¬í•˜ëŠ” ëŠ¥ë ¥ì´ â€œì½”ë“œ ìƒì„±â€ì¸ì§€ â€œì½”ë“œ ë¦¬ë·°/ì¶”ë¡ â€ì¸ì§€ì— ë”°ë¼ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì„ì–´ì•¼ í•©ë‹ˆë‹¤.

---

## ğŸš€ ë§ˆë¬´ë¦¬
MMLUì™€ HumanEvalì€ ì—¬ì „íˆ ìœ ìš©í•˜ì§€ë§Œ, 2026ë…„ 2ì›” ê¸°ì¤€ìœ¼ë¡œëŠ” ë”ë”ìš± **â€œì ìˆ˜â€ë³´ë‹¤ â€œí‰ê°€ í”„ë¡œí† ì½œâ€ì´ ë³¸ì²´**ì…ë‹ˆë‹¤.  
- MMLUëŠ” `instruct/logits/pro` ë“± ë³€í˜•ê³¼ í…œí”Œë¦¿/ìƒ· ìˆ˜ê°€ ì ìˆ˜ í•´ì„ì„ ë°”ê¾¸ê³  ([docs.nvidia.com](https://docs.nvidia.com/nemo/evaluator/latest/evaluation/benchmarks/catalog/all/harnesses/lm-evaluation-harness.html))  
- HumanEvalì€ ì‹¤í–‰ í™˜ê²½ê³¼ ì¶œë ¥ íŒŒì‹± ê·œì¹™, ê·¸ë¦¬ê³  pass@k ìƒ˜í”Œë§ ì •ì±…ì´ ì„±ëŠ¥ì„ ë§Œë“ ë‹¤ ([deepwiki.com](https://deepwiki.com/EleutherAI/lm-evaluation-harness/3.4-code-generation-tasks?utm_source=openai))  

ë‹¤ìŒ í•™ìŠµ/í™•ì¥ìœ¼ë¡œëŠ”:
- `lm-evaluation-harness`ì—ì„œ íƒœìŠ¤í¬ ì •ì˜(yaml)ì™€ ì±„ì  ì½”ë“œë¥¼ ì§ì ‘ ì½ê³ , íŒ€ í‘œì¤€ â€œí‰ê°€ í”„ë¡œí•„â€(í…œí”Œë¦¿/ìƒ·/ë””ì½”ë”©/ë²„ì „)ì„ ê³ ì •í•´ ë‚´ë¶€ ë¦¬ë”ë³´ë“œë¥¼ ìš´ì˜í•´ë³´ì„¸ìš”. ([github.com](https://github.com/EleutherAI/lm-evaluation-harness/releases))
---
title: "LoRA vs QLoRA, 2026ë…„ 1ì›” ê¸°ì¤€ â€œì§„ì§œ íš¨ìœ¨â€ë¡œ LLM Fine-tuning í•˜ëŠ” ë²• (ì›ë¦¬+ì‹¤ì „ì½”ë“œ)"
date: 2026-01-28 02:25:10 +0900
categories: [AI, LLM]
tags: [ai, llm, trend, 2026-01]
---

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7990TVG7C7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7990TVG7C7');
</script>

## ë“¤ì–´ê°€ë©°
2026ë…„ì—ë„ LLM fine-tuningì˜ ë³¸ì§ˆì€ ë³€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. **ì„±ëŠ¥(ë„ë©”ì¸ ì í•©ë„)**ì„ ì˜¬ë¦¬ê³  ì‹¶ì§€ë§Œ, **GPU VRAM/í•™ìŠµ ì‹œê°„/ìš´ì˜ ë¹„ìš©**ì´ ë°œëª©ì„ ì¡ìŠµë‹ˆë‹¤. Full fine-tuningì€ 7Bë§Œ ê°€ë„ ë©”ëª¨ë¦¬ ë¶€ë‹´ì´ ê¸‰ê²©íˆ ì»¤ì§€ê³ (ê°€ì¤‘ì¹˜+gradient+optimizer state), ì‹¤ë¬´ì—ì„œëŠ” â€œì¼ë‹¨ ëŒì•„ê°€ëŠ”â€ íš¨ìœ¨ì  ë°©ë²•ì´ í•„ìš”í•©ë‹ˆë‹¤. ([arxiv.org](https://arxiv.org/abs/2601.02609?utm_source=openai))

ì´ë•Œ ê°€ì¥ í˜„ì‹¤ì ì¸ í•´ë²•ì´ **LoRA / QLoRA**ì…ë‹ˆë‹¤. LoRAëŠ” ì—…ë°ì´íŠ¸ íŒŒë¼ë¯¸í„°ë¥¼ â€œì €ë­í¬(low-rank)â€ë¡œ ì œí•œí•´ í•™ìŠµ ë¹„ìš©ì„ ì¤„ì´ê³ , QLoRAëŠ” ì—¬ê¸°ì— **4-bit quantization**ì„ ë”í•´ **ë” í° ëª¨ë¸ì„ ë” ì‘ì€ VRAMì—ì„œ** fine-tuning ê°€ëŠ¥í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. ([unsloth.ai](https://unsloth.ai/docs/get-started/fine-tuning-llms-guide?utm_source=openai))

---

## ğŸ”§ í•µì‹¬ ê°œë…
### 1) LoRA: â€œê°€ì¤‘ì¹˜ ì „ì²´â€ ëŒ€ì‹  â€œì €ë­í¬ ì–´ëŒ‘í„°â€ë§Œ í•™ìŠµ
LoRAì˜ í•µì‹¬ì€ ì„ í˜•ì¸µì˜ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ ì§ì ‘ í•™ìŠµí•˜ì§€ ì•Šê³ , ì•„ë˜ì²˜ëŸ¼ **ì €ë­í¬ í–‰ë ¬ A,Bë¡œ ë¶„í•´ëœ ë¸íƒ€(Î”W)**ë§Œ í•™ìŠµí•˜ëŠ” ê²ë‹ˆë‹¤.

- ì›ë˜: `W` ì „ì²´ë¥¼ ì—…ë°ì´íŠ¸ (ë¹„ì‹¸ê³  ë©”ëª¨ë¦¬ ë§ì´ ë“¦)
- LoRA: `W' = W + Î”W`, ê·¸ë¦¬ê³  `Î”W = B @ A` (rank r, râ‰ªd)

ì´ë ‡ê²Œ í•˜ë©´ í•™ìŠµí•´ì•¼ í•  íŒŒë¼ë¯¸í„° ìˆ˜ê°€ í¬ê²Œ ì¤„ê³ , checkpointë„ â€œì–´ëŒ‘í„°ë§Œâ€ ì €ì¥í•  ìˆ˜ ìˆì–´ ë°°í¬/ë¡¤ë°±ë„ ì‰¬ì›Œì§‘ë‹ˆë‹¤.

ì¶”ê°€ë¡œ 2025~2026 íë¦„ì—ì„œ ì¤‘ìš”í•œ í¬ì¸íŠ¸ê°€ ë‘ ê°€ì§€:
- **rsLoRA**: scalingì„ `lora_alpha/r` ëŒ€ì‹  `lora_alpha/sqrt(r)`ë¡œ ì•ˆì •í™”í•´ ê³ ë­í¬ì—ì„œ ì„±ëŠ¥ ì ì¬ë ¥ì„ ë” ëŒì–´ì˜¬ë¦¬ëŠ” ì ‘ê·¼ ([huggingface.co](https://huggingface.co/docs/peft/main/developer_guides/lora?utm_source=openai))  
- **LoRA-FA optimizer**: LoRA í•™ìŠµì—ì„œ activation memoryë¥¼ ì¤„ì—¬ VRAM íš¨ìœ¨ì„ ë” ê°œì„ (ë­í¬ ì˜¬ë ¤ë„ ë©”ëª¨ë¦¬ ì¦ê°€ ë‘”ê°) ([huggingface.co](https://huggingface.co/docs/peft/main/en/developer_guides/lora?utm_source=openai))  

### 2) QLoRA: 4-bitë¡œ â€œë² ì´ìŠ¤ ëª¨ë¸â€ì„ ë“¤ê³  ì˜¤ê³ , LoRAë§Œ í•™ìŠµ
QLoRAëŠ” ë² ì´ìŠ¤ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ **4-bitë¡œ quantize**í•´ì„œ GPUì— ì˜¬ë¦¬ê³ , í•™ìŠµì€ LoRA adapter(ëŒ€ê°œ 16-bit/bf16)ë§Œ í•©ë‹ˆë‹¤. í•µì‹¬ ì˜µì…˜ë“¤ì´ ì‹¤ì „ í’ˆì§ˆì„ ì¢Œìš°í•©ë‹ˆë‹¤.

- **NF4**: QLoRA ë…¼ë¬¸ ê³„ì—´ì—ì„œ ê¶Œì¥ë˜ëŠ” 4-bit íƒ€ì…. í•™ìŠµìš© 4-bit baseì—ëŠ” NF4 ê¶Œì¥ ([huggingface.co](https://huggingface.co/docs/transformers/main/quantization/bitsandbytes?utm_source=openai))  
- **compute dtype**: 4-bit ì €ì¥ + bf16 ê³„ì‚°(ì˜ˆ: `bnb_4bit_compute_dtype=torch.bfloat16`)ë¡œ ì†ë„/ì•ˆì •ì„± íƒ€í˜‘ ([huggingface.co](https://huggingface.co/docs/transformers/main/quantization/bitsandbytes?utm_source=openai))  
- **(Nested) double quantization**: 4-bit ì–‘ìí™”ì— ì¶”ê°€ ìµœì í™”ë¥¼ ì–¹ëŠ” ê³„ì—´(ì„¤ì •ì— ë”°ë¼ VRAM ì ˆê°) ([huggingface.co](https://huggingface.co/docs/transformers/main/quantization/bitsandbytes?utm_source=openai))  

ë˜, PEFT ìª½ì—ì„œëŠ” QLoRA ì„±ëŠ¥ì„ ëŒì–´ì˜¬ë¦¬ëŠ” â€œì´ˆê¸°í™”â€ë„ ê°•ì¡°ë©ë‹ˆë‹¤.
- **LoftQ**: quantization errorë¥¼ ì¤„ì´ë„ë¡ LoRAë¥¼ ì´ˆê¸°í™”. íŠ¹íˆ `target_modules="all-linear"` + `nf4` ì¡°í•©ì´ ê¶Œì¥ë˜ëŠ” íë¦„ ([huggingface.co](https://huggingface.co/docs/peft/main/en/developer_guides/lora?utm_source=openai))  

---

## ğŸ’» ì‹¤ì „ ì½”ë“œ
ì•„ë˜ ì˜ˆì œëŠ” **Transformers + PEFT + bitsandbytes** ì¡°í•©ìœ¼ë¡œ, â€œ4-bit(Q)LoRA SFTâ€ë¥¼ ìµœì†Œ êµ¬ì„±ìœ¼ë¡œ ëŒë¦¬ëŠ” í˜•íƒœì…ë‹ˆë‹¤. (ëŒ€í™”í˜• ë°ì´í„°ë¼ë©´ chat template ì ìš©ì„ ê¶Œì¥)

```python
import torch
from datasets import load_dataset
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    BitsAndBytesConfig,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling,
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training

# 1) 4-bit quantization config (QLoRA í•µì‹¬)
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",              # í•™ìŠµìš© baseëŠ” NF4 ê¶Œì¥
    bnb_4bit_compute_dtype=torch.bfloat16,  # bf16 computeë¡œ ì†ë„/ì•ˆì •ì„±
    bnb_4bit_use_double_quant=True,         # nested/double quant ê³„ì—´
)

base_model_id = "meta-llama/Meta-Llama-3-8B-Instruct"  # ì˜ˆì‹œ: ë¼ì´ì„ ìŠ¤/ì ‘ê·¼ ê¶Œí•œ í™•ì¸ í•„ìš”
tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

model = AutoModelForCausalLM.from_pretrained(
    base_model_id,
    quantization_config=bnb_config,
    device_map="auto",
)

# 2) k-bit training ì¤€ë¹„: LayerNorm ìºìŠ¤íŒ…/gradient checkpoint ë“± ì•ˆì •í™” ì„¤ì •ì— ê´€ì—¬
model = prepare_model_for_kbit_training(model)

# 3) LoRA ì„¤ì •
# - target_modulesëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ì— ë”°ë¼ ë‹¤ë¦„(q_proj/v_proj ë“±). "all-linear"ëŠ” í­ ë„“ê²Œ ë¨¹ì´ëŠ” ì˜µì…˜.
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear",
)

model = get_peft_model(model, lora_config)
model.print_trainable_parameters()

# 4) ë°ì´í„°: ì˜ˆì‹œëŠ” HF datasetì˜ text ì»¬ëŸ¼ì´ ìˆë‹¤ê³  ê°€ì •
#    ì‹¤ë¬´ì—ì„œëŠ” ChatML/ShareGPTë¥¼ "prompt + response"ë¡œ ëª…í™•íˆ í¬ë§·í•˜ê³ ,
#    response ë¶€ë¶„ë§Œ lossë¥¼ ì£¼ëŠ” ë°©ì‹ì´ í’ˆì§ˆ/ì•ˆì „ì„±ì— ìœ ë¦¬í•œ ê²½ìš°ê°€ ë§ìŒ.
ds = load_dataset("Abirate/english_quotes")  # ì˜ˆì‹œ ë°ì´í„°
def tokenize_fn(ex):
    return tokenizer(
        ex["quote"],
        truncation=True,
        max_length=256,
        padding="max_length",
    )

train_ds = ds["train"].select(range(2000)).map(tokenize_fn, remove_columns=ds["train"].column_names)

data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

# 5) í•™ìŠµ ì„¤ì •
args = TrainingArguments(
    output_dir="./qlora-adapter-out",
    per_device_train_batch_size=2,
    gradient_accumulation_steps=8,  # VRAM ë¶€ì¡±í•˜ë©´ ëŠ˜ë ¤ì„œ effective batch í™•ë³´
    learning_rate=2e-4,
    num_train_epochs=1,
    logging_steps=20,
    save_steps=200,
    bf16=True,                      # ê°€ëŠ¥í•˜ë©´ bf16 ê¶Œì¥(í™˜ê²½ ë”°ë¼ fp16)
    optim="paged_adamw_8bit",        # bitsandbytes ê³„ì—´ optimizer (í™˜ê²½ì— ë”°ë¼ ê°€ìš©ì„± í™•ì¸)
    report_to="none",
)

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_ds,
    data_collator=data_collator,
)

trainer.train()

# 6) ê²°ê³¼ ì €ì¥: baseëŠ” ê·¸ëŒ€ë¡œ, LoRA adapterë§Œ ì €ì¥í•˜ëŠ” ê²Œ ì¼ë°˜ì 
model.save_pretrained("./qlora-adapter-out/adapter")
tokenizer.save_pretrained("./qlora-adapter-out/adapter")
```

ì°¸ê³ ë¡œ ì‹¤ë¬´ ê´€ì ì—ì„  â€œí•™ìŠµì´ ì •ë§ ì§„í–‰ ì¤‘ì¸ì§€â€ë¥¼ **gradient norm / loss curve**ë¡œ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ìµœê·¼ì—ëŠ” íŠ¹ì • í”„ë ˆì„ì›Œí¬ ë²¤ì¹˜ë§ˆí¬ê°€ â€œì‹¤ì œë¡œëŠ” í•™ìŠµì´ ì•ˆ ë„ëŠ” ìƒíƒœâ€ì˜€ë‹¤ëŠ” ì§€ì ë„ ë‚˜ì™”ìŠµë‹ˆë‹¤. ([arxiv.org](https://arxiv.org/abs/2601.02609?utm_source=openai))

---

## âš¡ ì‹¤ì „ íŒ
- **NF4 + bf16 computeëŠ” ì‚¬ì‹¤ìƒ ê¸°ë³¸ê°’**ì²˜ëŸ¼ êµ³ì–´ì¡ŒìŠµë‹ˆë‹¤. í•™ìŠµìš© 4-bit baseì—ì„œëŠ” NF4ê°€ ê¶Œì¥ë©ë‹ˆë‹¤. ([huggingface.co](https://huggingface.co/docs/transformers/main/quantization/bitsandbytes?utm_source=openai))  
- **target_modulesë¥¼ ë³´ìˆ˜ì ìœ¼ë¡œ ì‹œì‘í•˜ì§€ ë§ˆì„¸ìš”**: QLoRAì—ì„œ â€œëª‡ ê°œ ë ˆì´ì–´ë§Œâ€ LoRAë¥¼ ê±¸ë©´ ìš©ëŸ‰ì€ ì¤„ì§€ë§Œ ì„±ëŠ¥ì´ ê¸‰ê²©íˆ êº¾ì´ëŠ” ì¼€ì´ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤. LoftQë„ â€œë§ì´ íƒ€ê²ŸíŒ…í• ìˆ˜ë¡â€ ìœ ë¦¬í•œ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤. ([huggingface.co](https://huggingface.co/docs/peft/main/en/developer_guides/lora?utm_source=openai))  
- **LoRA rank(r)ëŠ” â€˜í’ˆì§ˆ vs ë¹„ìš©â€™ì˜ ë ˆë²„**: r=8/16/32ë¥¼ ë¹ ë¥´ê²Œ ìŠ¤ìœ•í•˜ê³ , rsLoRA/LoRA-FA ê°™ì€ ìµœì‹  ì˜µì…˜ìœ¼ë¡œ â€œë­í¬ë¥¼ ì˜¬ë ¸ì„ ë•Œì˜ ì´ë“â€ì„ íšŒìˆ˜í•˜ëŠ” ì „ëµì´ ì¢‹ìŠµë‹ˆë‹¤. ([huggingface.co](https://huggingface.co/docs/peft/main/developer_guides/lora?utm_source=openai))  
- **â€œí† í° íŒ¨ë”© ë‚­ë¹„â€ê°€ í•™ìŠµë¹„ë¥¼ ì¡ì•„ë¨¹ìŠµë‹ˆë‹¤**: sequence packing(ê¸¸ì´ ë¹„ìŠ·í•œ ìƒ˜í”Œì„ ë¬¶ì–´ íŒ¨ë”© ìµœì†Œí™”)ì„ ë„ì…í•˜ë©´ ì²´ê° ì†ë„ê°€ í¬ê²Œ ì˜¤ë¦…ë‹ˆë‹¤. ìµœì‹  í”„ë ˆì„ì›Œí¬ë“¤ì€ ì´ê±¸ í•µì‹¬ ìµœì í™”ë¡œ ë‚´ì„¸ì›ë‹ˆë‹¤. ([arxiv.org](https://arxiv.org/abs/2601.02609?utm_source=openai))  
- **ë¡œê·¸/ì¬í˜„ì„±ì€ ì„ íƒì´ ì•„ë‹ˆë¼ í•„ìˆ˜**: MLflow ê°™ì€ íˆ´ë¡œ íŒŒë¼ë¯¸í„°Â·ë©”íŠ¸ë¦­Â·ì•„í‹°íŒ©íŠ¸ë¥¼ ë‚¨ê²¨ì•¼ â€œì™œ ì¢‹ì•„ì¡ŒëŠ”ì§€/ë‚˜ë¹ ì¡ŒëŠ”ì§€â€ë¥¼ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ PEFT ëª¨ë¸ ë¡œê¹… ìš”êµ¬ ë²„ì „ ì¡°ê±´ë„ ìˆìœ¼ë‹ˆ ë¬¸ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”. ([mlflow.org](https://mlflow.org/docs/latest/ml/deep-learning/transformers/tutorials/fine-tuning/transformers-peft/?utm_source=openai))  

---

## ğŸš€ ë§ˆë¬´ë¦¬
ì •ë¦¬í•˜ë©´,
- **LoRA**ëŠ” â€œí•™ìŠµ íŒŒë¼ë¯¸í„° ìì²´ë¥¼ ì¤„ì—¬â€ fine-tuning ë¹„ìš©ì„ ë‚®ì¶”ê³ ,
- **QLoRA**ëŠ” â€œë² ì´ìŠ¤ ëª¨ë¸ì„ 4-bitë¡œ ë“¤ê³  ì™€ì„œâ€ ë” í° ëª¨ë¸ì„ ì‘ì€ VRAMì—ì„œ ë‹¤ë£¨ê²Œ í•´ì¤ë‹ˆë‹¤. ([unsloth.ai](https://unsloth.ai/docs/get-started/fine-tuning-llms-guide?utm_source=openai))  

ë‹¤ìŒ í•™ìŠµìœ¼ë¡œëŠ” (1) PEFTì˜ **LoftQ/rsLoRA/LoRA-FA** ê°™ì€ â€œí’ˆì§ˆÂ·íš¨ìœ¨ ê°œì„  ì˜µì…˜â€ì„ ì‹¤ì œ ë°ì´í„°ì…‹ì—ì„œ ablationìœ¼ë¡œ ë¹„êµí•˜ê³  ([huggingface.co](https://huggingface.co/docs/peft/main/en/developer_guides/lora?utm_source=openai)), (2) padding ë‚­ë¹„ë¥¼ ì¤„ì´ëŠ” **packing**ê³¼ í•™ìŠµì´ â€œì§„ì§œë¡œâ€ ë˜ê³  ìˆëŠ”ì§€ ê²€ì¦í•˜ëŠ” **gradient/loss sanity check**ë¥¼ íŒŒì´í”„ë¼ì¸ì— ê³ ì •ìœ¼ë¡œ ë„£ëŠ” ê±¸ ì¶”ì²œí•©ë‹ˆë‹¤. ([arxiv.org](https://arxiv.org/abs/2601.02609?utm_source=openai))